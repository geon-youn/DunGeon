{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-04-20-Recurrent-Neural-Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \"What are Recurrent Neural Networks?\"\n",
        "> \"Wait it's all a fancy loop?\"\n",
        "\n",
        "- comments: true\n",
        "- categories: [nlp]"
      ],
      "metadata": {
        "id": "Zm_gCBcah3iW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tb1boMv-h1Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6c45f7-076c-4d0e-d1a1-53674f932e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "!pip install -Uqq fastai>=2.0.0 graphviz ipywidgets matplotlib nbdev>=0.2.12 pandas scikit_learn azure-cognitiveservices-search-imagesearch sentencepiece\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a [previous blog](https://geon-youn.github.io/DunGeon/nlp/2022/04/08/Movie-Review-Sentiment.html), we used a pretrained model that used the AWD-LSTM architecture. This architecture is built off a recurrent neural network. \"Recurrent\", according to Cambridge Dictionary means \"happening again many times\". And it just so happens that a recurrent neural network is a neural network with layers that happen again (repeat) many times. \n",
        "\n",
        "To go over RNNs in this blog, we'll be using the human numbers data set that contains the first 10,000 numbers written out in English.\n",
        "\n",
        "We'll download the data set from fastai's `URLs` class:"
      ],
      "metadata": {
        "id": "wx5hNS2DSnpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hide_output \n",
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ],
      "metadata": {
        "id": "XAQwCSDGvcEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "80ce4516-1909-44d8-cb67-b216cde179ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "YtBO-fRCvjw7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll see how the data set is laid out:"
      ],
      "metadata": {
        "id": "GyGaZ-Rj1m6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5u0DL6vpqX",
        "outputId": "5c479d8c-6718-4cb7-811a-1a12faf56ac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('train.txt'),Path('valid.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's two text files that contain the numbers. Since we're creating a language model, we'll concatenate them:"
      ],
      "metadata": {
        "id": "Mx2J0NNH1rao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: \n",
        "    lines += L(f.readlines())\n",
        "with open(path/'valid.txt') as f:\n",
        "    lines += L(f.readlines())\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90IngcOOvxEE",
        "outputId": "865a3e50-4151-4ae1-85e2-17cb738992d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can join the lines together, separated by dots so that we can tokenize them:"
      ],
      "metadata": {
        "id": "lvqSTklS1vyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' . '.join([i.strip() for i in lines])\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LpDRqedFwS3V",
        "outputId": "06b5674e-51ea-42ee-9bcb-15654cc0ada5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll then tokenize them by splitting them according to spaces:"
      ],
      "metadata": {
        "id": "Og9VRzGO11e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhf5I-3jwnEP",
        "outputId": "7069fe5b-9564-48a5-f3b2-c82d2455f035"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first joined them with a period instead of spaces because the spaces between the words are significant. We want to separate numbers, not words, as in, we want this:"
      ],
      "metadata": {
        "id": "sq-s6Vu12Qjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text[text.rindex('.'):]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mrdjhCj_2Zos",
        "outputId": "d23c60ec-2b30-49d6-ff68-f71b5371d243"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'. nine thousand nine hundred ninety nine'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not this:\n",
        "\n",
        "    nine . thousand . nine . hundred . ninety . nine"
      ],
      "metadata": {
        "id": "Am_VW-oA2o52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create our vocab by making a list of the unique tokens:"
      ],
      "metadata": {
        "id": "G5WuyYry2w5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = L(tokens).unique()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy9J3PogwraH",
        "outputId": "94f9cc26-7930-4952-d7f5-dc1f3e0b1d9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then we'll numericalize the tokens. In this blog, we'll be keeping the notation of `input_target` like \"input\" to (_) \"target\", so `t_i` means token to index:"
      ],
      "metadata": {
        "id": "ejATyJ-Z21mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_i  = {t: i for i, t in enumerate(vocab)}\n",
        "nums = L(t_i[t] for t in tokens)\n",
        "nums[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbixA530w9VK",
        "outputId": "79b6b8bd-efff-4b38-80d1-bb8d4fd75e25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [0,1,2,1,3,1,4,1,5,1]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want our model to predict the next word given the last 3 words in the sequence, so we can do that with just Python:"
      ],
      "metadata": {
        "id": "FS1Zdyo23T8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqs_tok = L((tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-4, 3))\n",
        "seqs_tok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiGtQFBmxV6q",
        "outputId": "62a6eb24-5a18-473b-9f0e-69d7f598ea8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And since it looks right with the tokens, we'll do the same with the numericalized tokens (and it should look like the above, but with numericalized tokens instead):"
      ],
      "metadata": {
        "id": "6UgkDJU93b_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0, len(nums)-4, 3))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sk121i3xnSo",
        "outputId": "34045f0a-8d16-4343-e672-04017078064f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll make our `DataLoaders`:"
      ],
      "metadata": {
        "id": "--4OR2223fon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ],
      "metadata": {
        "id": "rMuNwkIAxx4E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And check that we can make a batch:"
      ],
      "metadata": {
        "id": "nCsDpeZsXTk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse_output\n",
        "dls.one_batch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOhO5fPwytKy",
        "outputId": "1bd17c77-235c-4efb-fc84-ad8363d3d1a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2],\n",
              "         [ 1,  3,  1],\n",
              "         [ 4,  1,  5],\n",
              "         [ 1,  6,  1],\n",
              "         [ 7,  1,  8],\n",
              "         [ 1,  9,  1],\n",
              "         [10,  1, 11],\n",
              "         [ 1, 12,  1],\n",
              "         [13,  1, 14],\n",
              "         [ 1, 15,  1],\n",
              "         [16,  1, 17],\n",
              "         [ 1, 18,  1],\n",
              "         [19,  1, 20],\n",
              "         [ 1, 20,  0],\n",
              "         [ 1, 20,  2],\n",
              "         [ 1, 20,  3],\n",
              "         [ 1, 20,  4],\n",
              "         [ 1, 20,  5],\n",
              "         [ 1, 20,  6],\n",
              "         [ 1, 20,  7],\n",
              "         [ 1, 20,  8],\n",
              "         [ 1, 20,  9],\n",
              "         [ 1, 21,  1],\n",
              "         [21,  0,  1],\n",
              "         [21,  2,  1],\n",
              "         [21,  3,  1],\n",
              "         [21,  4,  1],\n",
              "         [21,  5,  1],\n",
              "         [21,  6,  1],\n",
              "         [21,  7,  1],\n",
              "         [21,  8,  1],\n",
              "         [21,  9,  1],\n",
              "         [22,  1, 22],\n",
              "         [ 0,  1, 22],\n",
              "         [ 2,  1, 22],\n",
              "         [ 3,  1, 22],\n",
              "         [ 4,  1, 22],\n",
              "         [ 5,  1, 22],\n",
              "         [ 6,  1, 22],\n",
              "         [ 7,  1, 22],\n",
              "         [ 8,  1, 22],\n",
              "         [ 9,  1, 23],\n",
              "         [ 1, 23,  0],\n",
              "         [ 1, 23,  2],\n",
              "         [ 1, 23,  3],\n",
              "         [ 1, 23,  4],\n",
              "         [ 1, 23,  5],\n",
              "         [ 1, 23,  6],\n",
              "         [ 1, 23,  7],\n",
              "         [ 1, 23,  8],\n",
              "         [ 1, 23,  9],\n",
              "         [ 1, 24,  1],\n",
              "         [24,  0,  1],\n",
              "         [24,  2,  1],\n",
              "         [24,  3,  1],\n",
              "         [24,  4,  1],\n",
              "         [24,  5,  1],\n",
              "         [24,  6,  1],\n",
              "         [24,  7,  1],\n",
              "         [24,  8,  1],\n",
              "         [24,  9,  1],\n",
              "         [25,  1, 25],\n",
              "         [ 0,  1, 25],\n",
              "         [ 2,  1, 25]]),\n",
              " tensor([ 1,  4,  1,  7,  1, 10,  1, 13,  1, 16,  1, 19,  1,  1,  1,  1,  1,  1,\n",
              "          1,  1,  1,  1, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,  0,  2,  3,  4,\n",
              "          5,  6,  7,  8,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 24, 24, 24,\n",
              "         24, 24, 24, 24, 24, 24, 25,  0,  2,  3]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a model that takes in 3 words as input and tries to predict the next word, we can:\n",
        "1. Calculate the embeddings for the first word,\n",
        "2. Pass the embeddings into a linear layer,\n",
        "3. Apply a nonlinearity (like ReLU or softmax),\n",
        "4. Calculate the embeddings for the second word,\n",
        "5. Add the embeddings to the activations from step 3,\n",
        "6. Pass the activations into the same linear layer in step 2,\n",
        "7. Apply a nonlinearity, and\n",
        "8. Repeat steps 4 to 7 with the third word. \n",
        "\n",
        "By adding the next word's embeddings to the previous activations, every word is interpreted in the context of the preceding words. And, we use the same weight matrix (linear layer) since the way one word influences the activations from the previous words shouldn't change depending on the position of the word; so, we force the layer to learn all positions instead of limiting each layer to one position. \n",
        "\n",
        "To turn this idea into code, we can make a model by inheriting from PyTorch's `Module` class:"
      ],
      "metadata": {
        "id": "Y5nlXlmYvPTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNish(Module):\n",
        "    \"\"\"\n",
        "    We have three different states:\n",
        "      -  Input  (the words)\n",
        "      -  Hidden (activations)\n",
        "      -  Output (the probabilities for the next word)\n",
        "    \n",
        "    We then have three different layers:\n",
        "      -  i_h: input to hidden\n",
        "           -  The embedding matrix to turn our words into embeddings\n",
        "      -  h_h: hidden to hidden\n",
        "           -  Calculates the activations for the next word\n",
        "      -  h_o: hidden to output\n",
        "           -  Calculates the predictions for the next word\n",
        "    \"\"\"\n",
        "    def __init__(self, n_vocab, n_hidden):\n",
        "        self.i_h = nn.Embedding(n_vocab, n_hidden)\n",
        "        # If we want a more complex model, \n",
        "        # we would be altering this\n",
        "        # hidden to hidden layer into more layers\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, n_vocab)\n",
        "\n",
        "    # This is what our steps would look like\n",
        "    def forward(self, x):\n",
        "        h = self.i_h(x[:,0])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,1]) \n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2]) \n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "StaUXaNmVHos"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you took any intro to CS course, you might've had a point where you didn't learn `while` loops yet so you were copy pasting `if` statements and changing a couple numbers here and there. Well, we know loops so we turn our repetitive \"calculate the next embeddings, add it to the hidden state, then calculate the next activations\" into a loop.\n",
        "\n",
        "A *hidden state* is the activations that're updated at each step of a recurrent neural network (which we can see below in the `for` loop): "
      ],
      "metadata": {
        "id": "xSVOlP6datwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(Module):\n",
        "    def __init__(self, n_vocab, n_hidden):\n",
        "        self.i_h = nn.Embedding(n_vocab, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, n_vocab)\n",
        "\n",
        "    # This is how we can simplify to turn it\n",
        "    # into a recurrent (looped) neural network\n",
        "    def forward(self, x):\n",
        "        # We can set it to 0 because tensors have\n",
        "        # a thing called \"broadcasting\" that tries\n",
        "        # to expand the smaller shape tensor into\n",
        "        # the same shape as the other one\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "oyedblTdbGSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, a recurrent neural network is a neural network that's defined using a loop, hence *recurrent*. An RNN that isn't using a loop like `RNNish` is the *unrolled representation* of an RNN. \n",
        "\n",
        "When we train a model with these two architectures, we should have about the same accuracy:"
      ],
      "metadata": {
        "id": "OYN0RM12cpj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNNish(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "0CcOcOaqy11O",
        "outputId": "8ec6e5e6-c149-47b7-f4f4-7e0946165df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.794642</td>\n",
              "      <td>1.953518</td>\n",
              "      <td>0.473497</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.401166</td>\n",
              "      <td>1.721939</td>\n",
              "      <td>0.475398</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.425844</td>\n",
              "      <td>1.658773</td>\n",
              "      <td>0.492750</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.379972</td>\n",
              "      <td>1.654874</td>\n",
              "      <td>0.490373</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "gzJN14dZ0smL",
        "outputId": "e1e609aa-f565-4614-eff6-1224903a8fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.852343</td>\n",
              "      <td>1.971172</td>\n",
              "      <td>0.464226</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.371547</td>\n",
              "      <td>1.797724</td>\n",
              "      <td>0.475160</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.413824</td>\n",
              "      <td>1.689967</td>\n",
              "      <td>0.491324</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.366402</td>\n",
              "      <td>1.645036</td>\n",
              "      <td>0.492988</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, we get about 49% for each. To see if it's actually good, we can compare it to if we just predicted the most commonly occurring token each time instead:"
      ],
      "metadata": {
        "id": "W97JokNw3vVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, counts = 0, torch.zeros(len(vocab))\n",
        "for x, y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab):\n",
        "        counts[i] += (y == i).long().sum()\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg8K634Q35E_",
        "outputId": "09293000-e2e2-4919-ec6a-6e0d68cb0cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, if we just predicted the most commonly occurring token, \"thousand\", each time, we would have an accuracy of 15%, so our basic language model with an accuracy of 49% is much better.\n",
        "\n",
        "You might be wondering, why don't you just use `h += ...` instead of `h = h + ...`? I thought so too, but you get a `RuntimeError` by PyTorch because you're using a tensor or its part to compute the tensor or its part; in other words, PyTorch can't calculate the gradient when you use `+=`. You can read more on why [here](https://nieznanm.medium.com/runtimeerror-one-of-the-variables-needed-for-gradient-computation-has-been-modified-by-an-inplace-85d0d207623)."
      ],
      "metadata": {
        "id": "5Ixj6QXM5Rrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the simple RNN"
      ],
      "metadata": {
        "id": "8t-jlUcbqnt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, we're initializing the hidden state `h` to 0 each time in `forward`. This effectively makes the model forget what it's seen before. To fix this, we can initialize `h` in `__init__` and create a `reset` function to reinitialize `h` to 0. \n",
        "\n",
        "But, this creates another problem: as we apply another layer to `h`, we add another thing on which we have to calculate the derivative during backpropagation. So, we can use PyTorch's `detach` method on `h`, which removes the gradient history of `h` (technically, it makes `h` no longer require gradient).\n",
        "\n",
        "Overall, we made our new RNN stateful since it remembers its activations between different samples in the batch (between different calls to `forward`):"
      ],
      "metadata": {
        "id": "7pQIGSKpqqdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN2(Module):\n",
        "    def __init__(self, n_vocab, n_hidden):\n",
        "        self.i_h = nn.Embedding(n_vocab, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, n_vocab)\n",
        "        self.h   = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out    = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "    \n",
        "    def reset(self):\n",
        "        self.h = 0"
      ],
      "metadata": {
        "id": "IjpcheGXuThG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also have any sequence length we want since we'll have the same activations each time. The only difference is that we only calculate the gradients on sequence length tokens in the past instead of all of them. This approach is called ***truncated* backpropagation through time** (truncated BPTT).\n",
        "\n",
        "BPTT is treating an RNN as one big model (which we did by initializing `h` to 0 in `__init__`), and calculating gradients on it the usual way. Truncated BPTT avoids running out of memory and time by \"detaching\" the history of computation steps in the hidden state every (or few) epochs (which we did by reinitializing `h` to 0 in `reset`). \n",
        "\n",
        "To make our model work, we need it to see the data set in order, such that `dset[0]` is in the first line of the first batch, `dset[1]` is in the first line of the second batch, and so on. For the other lines, we can split the data set into chunks of size `m = len(dset) // bs`, so `dset[i + j * m]` is in the `j+1`-th line of the `i+1`-th batch). This is done automatically in `LMDataLoader`. \n",
        "\n",
        "The following function does the reindexing:"
      ],
      "metadata": {
        "id": "03zmuCgdYY6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_chunks(dset, bs):\n",
        "    m = len(dset) // bs\n",
        "    new_dset = L()\n",
        "    for i in range(m):\n",
        "        new_dset += L(dset[i + j * m] for j in range(bs))\n",
        "    return new_dset"
      ],
      "metadata": {
        "id": "CTINsTxIf8yU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, when we make our `DataLoaders`, we also need to drop the last batch since it might not be of size `bs`. We also need to avoid shuffling the data since that would ruin the purpose of our reindexing."
      ],
      "metadata": {
        "id": "_2KNWYD_pZPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs  = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "        group_chunks(seqs[:cut], bs), \n",
        "        group_chunks(seqs[cut:], bs), \n",
        "        bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "LipQqhHNcTjl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to adjust the training loop so that we call `reset`. We can do this by adding `ModelResetter` as a `Callback` (`cbs`), which calls `reset` before each epoch and each validation phase. Since we reinitialize the hidden state, we start with a clean state before each batch so we can train for more epochs. "
      ],
      "metadata": {
        "id": "Z4H3KM6ypsAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IPCgp4z8ciS8",
        "outputId": "df066ebd-bc23-4079-bdf9-8c8496f578e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.739974</td>\n",
              "      <td>1.857636</td>\n",
              "      <td>0.474038</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.270585</td>\n",
              "      <td>1.779141</td>\n",
              "      <td>0.451683</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.106414</td>\n",
              "      <td>1.576123</td>\n",
              "      <td>0.522356</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.020932</td>\n",
              "      <td>1.581516</td>\n",
              "      <td>0.552644</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.954357</td>\n",
              "      <td>1.765170</td>\n",
              "      <td>0.551683</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.894364</td>\n",
              "      <td>1.761537</td>\n",
              "      <td>0.568510</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.850844</td>\n",
              "      <td>1.735529</td>\n",
              "      <td>0.553365</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.813397</td>\n",
              "      <td>1.583861</td>\n",
              "      <td>0.581010</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.766258</td>\n",
              "      <td>1.656481</td>\n",
              "      <td>0.605529</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.751839</td>\n",
              "      <td>1.691648</td>\n",
              "      <td>0.609135</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning it more like a language model"
      ],
      "metadata": {
        "id": "PBt812hznvFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember how when we took the movie review data set, we made the independent variable and dependent variable the same token length, but the dependent variable was ahead by one token? By doing so, we get more signal that we can feed back to the model when we update the weights. Why predict the last word of the sequence when you can predict the next word for each word in the sequence, right?\n",
        "\n",
        "So, we can adjust our `seqs` to be of `sl` length for both independent and dependent variables, with them offset by one token:"
      ],
      "metadata": {
        "id": "EHb9MZLhnx3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sl      = 16\n",
        "seqs_lm = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+1+sl]))\n",
        "            for i in range(0, len(nums)-1-sl, sl))\n",
        "[L(vocab[j] for j in seq) for seq in seqs_lm[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU1FFWwlonod",
        "outputId": "9388ce37-12d7-4017-cd23-5a37b4f46ed3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can make our `DataLoaders` the same way as before:"
      ],
      "metadata": {
        "id": "829GEDM4pfeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs  = 64\n",
        "cut = int(len(seqs_lm) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "        group_chunks(seqs_lm[:cut], bs), \n",
        "        group_chunks(seqs_lm[cut:], bs), \n",
        "        bs=bs, drop_last=True, shuffle=False)"
      ],
      "metadata": {
        "id": "9SJ2MX1zpibH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, we need to change our model so that it predicts after every word and not after the last one:"
      ],
      "metadata": {
        "id": "-qqJGryrpnds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN3(Module):\n",
        "    def __init__(self, n_vocab, n_hidden):\n",
        "        self.i_h = nn.Embedding(n_vocab, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, n_vocab)\n",
        "        self.h   = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        # We changed 3 to sl since we'll be\n",
        "        # predicting the next word sl times\n",
        "        for i in range(sl): \n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self):\n",
        "        self.h = 0"
      ],
      "metadata": {
        "id": "AFmZL5jrpusn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, we'll have to flatten the inputs and targets before using them in `F.cross_entropy`. The output of the model has a shape `bs` $\\times$ `sl` $\\times$ `n_vocab` since we stacked the output onto one dimension (through `dim=1`). Our targets have shape `bs` $\\times$ `sl`. So, we can reshape them using `torch.view`."
      ],
      "metadata": {
        "id": "ilyotHc4qKuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(input, target):\n",
        "    # .view(-1, len(vocab)) means make len(vocab)\n",
        "    # columns with as many rows as needed (-1)\n",
        "    #\n",
        "    # .view(-1) means flatten the entire tensor\n",
        "    # into one row that's as long as it needs to be\n",
        "    return F.cross_entropy(input.view(-1, len(vocab)), target.view(-1))"
      ],
      "metadata": {
        "id": "LnRSZG9Frr4L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can train our model. We'll have to use an even larger number of epochs than last time because we have a more complex model:"
      ],
      "metadata": {
        "id": "PKTKTT10zfPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN3(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "wYnTfDWbsSvW",
        "outputId": "f7f44636-0601-4643-a342-648ca375bd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.321696</td>\n",
              "      <td>3.182977</td>\n",
              "      <td>0.186442</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.411823</td>\n",
              "      <td>1.992369</td>\n",
              "      <td>0.469482</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.792959</td>\n",
              "      <td>1.769369</td>\n",
              "      <td>0.451253</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.494330</td>\n",
              "      <td>1.655577</td>\n",
              "      <td>0.501872</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.304660</td>\n",
              "      <td>1.634182</td>\n",
              "      <td>0.549967</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.152728</td>\n",
              "      <td>1.675661</td>\n",
              "      <td>0.584391</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.021364</td>\n",
              "      <td>1.745027</td>\n",
              "      <td>0.623698</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.910983</td>\n",
              "      <td>1.595549</td>\n",
              "      <td>0.588135</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.828727</td>\n",
              "      <td>1.685101</td>\n",
              "      <td>0.628092</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.753475</td>\n",
              "      <td>1.665891</td>\n",
              "      <td>0.615479</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.709412</td>\n",
              "      <td>1.602229</td>\n",
              "      <td>0.629069</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.660277</td>\n",
              "      <td>1.695538</td>\n",
              "      <td>0.648031</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.638024</td>\n",
              "      <td>1.641410</td>\n",
              "      <td>0.637695</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.617738</td>\n",
              "      <td>1.700257</td>\n",
              "      <td>0.645426</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.601591</td>\n",
              "      <td>1.764060</td>\n",
              "      <td>0.651204</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a better accuracy, but we have an effectively very deep network. So, we can end up with very small or very large gradients that can lead to very different results when we run train the model:"
      ],
      "metadata": {
        "id": "bKbmdyLbzeDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN3(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "5FXbEpK-zYLU",
        "outputId": "0bb9b649-5340-417f-b03c-7176baab9801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.209394</td>\n",
              "      <td>3.080578</td>\n",
              "      <td>0.263021</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.302940</td>\n",
              "      <td>1.904129</td>\n",
              "      <td>0.468262</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.727188</td>\n",
              "      <td>1.796725</td>\n",
              "      <td>0.468994</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.426145</td>\n",
              "      <td>1.770710</td>\n",
              "      <td>0.494548</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.230578</td>\n",
              "      <td>1.784142</td>\n",
              "      <td>0.498291</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.093605</td>\n",
              "      <td>1.889311</td>\n",
              "      <td>0.513591</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.975858</td>\n",
              "      <td>1.930008</td>\n",
              "      <td>0.532389</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.885223</td>\n",
              "      <td>2.018722</td>\n",
              "      <td>0.535319</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.814634</td>\n",
              "      <td>2.065933</td>\n",
              "      <td>0.538656</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.757224</td>\n",
              "      <td>2.108545</td>\n",
              "      <td>0.561686</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.712159</td>\n",
              "      <td>2.211724</td>\n",
              "      <td>0.544678</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.677356</td>\n",
              "      <td>2.263988</td>\n",
              "      <td>0.575033</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.650655</td>\n",
              "      <td>2.421612</td>\n",
              "      <td>0.533610</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.626848</td>\n",
              "      <td>2.389696</td>\n",
              "      <td>0.546549</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.614016</td>\n",
              "      <td>2.390650</td>\n",
              "      <td>0.552246</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By training a new model, we got a decrease of nearly 10% in accuracy. One way to fix this would be to try a deeper model: one with more than one linear layer between the hidden state and the output activations."
      ],
      "metadata": {
        "id": "X2ESA-fA0Ru_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More layers. MORE LAYERS. "
      ],
      "metadata": {
        "id": "_uhKMRcV0gMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multilayer RNN is more like a multiRNN model: we pass the activations from one RNN as inputs to another RNN. \n",
        "\n",
        "This time, instead of creating a `for` loop, we can use PyTorch's `nn.RNN` class, which implements it for us while also letting us choose how many layers we want:"
      ],
      "metadata": {
        "id": "Apy8ilre0uRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN4(Module):\n",
        "    def __init__(self, n_vocab, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(n_vocab, n_hidden)\n",
        "        # Our inputs are in order of (bs, sl, n_vocab) so we have to\n",
        "        # tell PyTorch we want bs first instead of sl first\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, n_vocab)\n",
        "        self.h   = torch.zeros(n_layers, bs, n_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        acts, h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h  = h.detach()\n",
        "        return self.h_o(acts)\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = self.h.zero_()"
      ],
      "metadata": {
        "id": "FwKQ5gqN1Ouy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, when we train our model, we get a worse accuracy than our previous single-layer RNN:"
      ],
      "metadata": {
        "id": "Jtd8L5oV3qn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN4(len(vocab), 64, 2), \n",
        "                # CrossEntropyLossFlat() does the \n",
        "                # same thing as our loss_func \n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "58E8N9i22Tsq",
        "outputId": "dfa90ad5-2745-45fb-c2d8-30b1b4788d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.089907</td>\n",
              "      <td>2.664662</td>\n",
              "      <td>0.444417</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.179285</td>\n",
              "      <td>1.815480</td>\n",
              "      <td>0.471354</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.719844</td>\n",
              "      <td>1.864228</td>\n",
              "      <td>0.323079</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.518661</td>\n",
              "      <td>1.860099</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.405865</td>\n",
              "      <td>1.868557</td>\n",
              "      <td>0.475911</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.304332</td>\n",
              "      <td>1.898743</td>\n",
              "      <td>0.479329</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.194302</td>\n",
              "      <td>2.151057</td>\n",
              "      <td>0.470785</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.086549</td>\n",
              "      <td>2.219379</td>\n",
              "      <td>0.503988</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.950983</td>\n",
              "      <td>2.215469</td>\n",
              "      <td>0.501709</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.839067</td>\n",
              "      <td>2.280946</td>\n",
              "      <td>0.510661</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.756243</td>\n",
              "      <td>2.429555</td>\n",
              "      <td>0.513021</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.699213</td>\n",
              "      <td>2.520038</td>\n",
              "      <td>0.525065</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.661544</td>\n",
              "      <td>2.569467</td>\n",
              "      <td>0.520671</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.639416</td>\n",
              "      <td>2.584662</td>\n",
              "      <td>0.521973</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.628166</td>\n",
              "      <td>2.575517</td>\n",
              "      <td>0.524089</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even when we add more layers, we get a worse accuracy than our single-layer RNN:"
      ],
      "metadata": {
        "id": "JBkS_Wgv3pV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, RNN4(len(vocab), 64, 5), \n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "NPFjLgCA3FJf",
        "outputId": "7f5c792d-105d-4671-b606-a9ee9f237b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.996651</td>\n",
              "      <td>2.546187</td>\n",
              "      <td>0.407471</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.138067</td>\n",
              "      <td>1.668146</td>\n",
              "      <td>0.470866</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.629905</td>\n",
              "      <td>1.733835</td>\n",
              "      <td>0.497965</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.352087</td>\n",
              "      <td>1.925911</td>\n",
              "      <td>0.537679</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.158306</td>\n",
              "      <td>1.992638</td>\n",
              "      <td>0.541992</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.996187</td>\n",
              "      <td>2.063406</td>\n",
              "      <td>0.544922</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.872516</td>\n",
              "      <td>2.011257</td>\n",
              "      <td>0.568848</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.745992</td>\n",
              "      <td>1.745594</td>\n",
              "      <td>0.566569</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.609336</td>\n",
              "      <td>1.654734</td>\n",
              "      <td>0.593099</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.494758</td>\n",
              "      <td>1.707728</td>\n",
              "      <td>0.603271</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.406440</td>\n",
              "      <td>1.617404</td>\n",
              "      <td>0.607747</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.343562</td>\n",
              "      <td>1.717202</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.304646</td>\n",
              "      <td>1.746353</td>\n",
              "      <td>0.599854</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.281399</td>\n",
              "      <td>1.724579</td>\n",
              "      <td>0.605794</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.268294</td>\n",
              "      <td>1.720216</td>\n",
              "      <td>0.603923</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason is that we now have an *even deeper* model, which are more likely to lead to exploding or vanishing activations. \n",
        "\n",
        "In practice, creating accurate models from multilayer RNNs are difficult because we're applying repeated matrix multiplication many, many times (each layer is another set of matrix multiplications). Multiplying by a number even a little greater than 1 will lead to exploding activations; and multiplying by a number even a little smaller than 1 will lead to vanishing activations. \n",
        "\n",
        "We also have the problem of floating point numbers. Because of how they're stored on the computer, the numbers are more accurate the closer they are to 0. This inaccuracy leads to the *vanishing gradients* or *exploding gradients* problem, where in SGD, the weights are either not updated at all, or explode to infinity.\n",
        "\n",
        "For RNNs, there're two types of layers that are commonly used to avoid exploding activations: *gated recurrent units* (GRUs) and *long short-term memory* (LSTM). "
      ],
      "metadata": {
        "id": "lpCKnTbH2TKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Long Short-Term Memory (LSTM)"
      ],
      "metadata": {
        "id": "g1PcqUAL5yo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM introduces another hidden state called the *cell state* that retains important information that happened earlier in the sentence (e.g., the subject's gender to predict \"he/she/they\"), that is, *long short-term memory*. The other hidden state is then like the *sensory short-term memory*. \n",
        "\n",
        "<figure>\n",
        "    <img src='https://www.researchgate.net/publication/336007475/figure/fig2/AS:808670514405376@1569813483041/Human-memory-system.png' alt='human memory'>\n",
        "    <figcaption>How human memory is theorized to work. Thank you IB psychology.</figcaption>\n",
        "</figure>\n",
        "\n",
        "So, LSTM looks like this:\n",
        "\n",
        "<figure>\n",
        "    <img src='https://www.frontiersin.org/files/Articles/402869/fnins-12-00745-HTML/image_m/fnins-12-00745-g001.jpg' alt='lstm'>\n",
        "    <figcaption>Diagram of LSTM. From left to right on the top, we have the forget gate, the input gate, the cell gate, and the output gate.</figcaption>\n",
        "</figure>\n",
        "\n",
        "In essence, the blue box is our `forward` function, which uses the previous hidden states $h_{t-1}$ and $c_{t-1}$ and accepts an input batch $x_t$. The function updates the hidden states to yield $h_t$ and $c_t$, which become $h_{(t+1)-1}$ and $c_{(t+1)-1}$ for the next time step. \n",
        "\n",
        "In LSTM, the hidden state $h_{t-1}$ and the input batch $x_t$ are concatenated instead of added like what we've been doing so far to create a tensor of size $h_{t-1}+x_t$. So, all the layers have an input size of $h_{t-1}+x_t$ and have an output size of $h_{t-1}$.\n",
        "\n",
        "LSTM has four layers called *gates*. There's two different activation functions being used in LSTM: sigmoid (squishes to 0 to 1) and tanh (squishes to -1 to 1). From left to right:\n",
        "- (1) Forget gate $f_t$: take what you currently know ($h_{t-1}$) and apply that to the input ($x_t$) to forget unimportant things in the cell state $c_{t-1}$.\n",
        "- (2) Input gate $i_t$ and (3) cell gate $g_t$: these two gates work together, so I'll group them together and call them the *remember gate*. Basically, take what you currently know ($h_{t-1}$) and apply that to the input ($x_t$) to remember the important stuff from the cell gate $g_t$. Add the output from the remember gate to the cell state.\n",
        "- (4) Output gate $o_t$: take important things from the new cell state that we might need for the next time step $t$.\n",
        "\n",
        "The *importance* mentioned above is what's learned when we train the model at each time step (i.e. epoch). \n",
        "\n",
        "The cell state $c_t$ is able to remember stuff much better (maintain a longer-term state) than the hidden state $h_t$ since it doesn't go through a single layer, hence avoiding vanishing and exploding activations. \n",
        "\n",
        "In code:"
      ],
      "metadata": {
        "id": "TYv9evhjlj7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(Module):\n",
        "    def __init__(self, n_in, n_hid):\n",
        "        n_cat            = n_in + n_hid\n",
        "        self.forget_gate = nn.Linear(n_cat, n_hid)\n",
        "        self.input_gate  = nn.Linear(n_cat, n_hid)\n",
        "        self.cell_gate   = nn.Linear(n_cat, n_hid)\n",
        "        self.output_gate = nn.Linear(n_cat, n_hid)\n",
        "    \n",
        "    def forward(self, x, state):\n",
        "        h, c = state\n",
        "        h    = torch.cat([h, x], dim=1)\n",
        "        f    = torch.sigmoid(self.forget_gate(h))\n",
        "        c    = c * f\n",
        "        i    = torch.sigmoid(self.input_gate(h))\n",
        "        g    = torch.tanh(self.cell_gate(h))\n",
        "        c    = c + i * g\n",
        "        o    = torch.sigmoid(self.output_gate(h))\n",
        "        h    = o * torch.tanh(c)\n",
        "        return h, (h, c)"
      ],
      "metadata": {
        "id": "9nYTnp8Krx8O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, in practice, we refactor the code since it's inefficient to do four small matrix multiplications when we can do one big multiplication on the GPU in parallel. It's like typing with a single finger when you were given 10 (unless you're missing fingers). Also, since it takes time to concatenate the input $x_t$ and the hidden state $h_t$, we have two layers instead: one for the input and one for the hidden state. So:"
      ],
      "metadata": {
        "id": "-kFYAibDvVU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(Module):\n",
        "    def __init__(self, n_in, n_hid):\n",
        "        self.i_h = nn.Linear(n_in,  4 * n_hid)\n",
        "        self.h_h = nn.Linear(n_hid, 4 * n_hid)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        h, c    = state\n",
        "        # .chunk(4, 1) splits the tensor into 4 tensors\n",
        "        # along the first dimension \n",
        "        gates   = (self.i_h(x) + self.h_h(h).chunk(4, 1))\n",
        "        # It doesn't matter what order the gates are \n",
        "        # as long as we keep the order throughout\n",
        "        f, i, o = map(torch.sigmoid, gates[:3])\n",
        "        g       = gates[3].tanh()\n",
        "\n",
        "        c = c * f + i * g\n",
        "        h = o * c.tanh()\n",
        "        return h, (h, c)"
      ],
      "metadata": {
        "id": "Rsj49UlZxn_O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, our `LSTM` is essentially what we already have through PyTorch's `nn.LSTM`. So, we can recreate our multilayer RNN:"
      ],
      "metadata": {
        "id": "u5x296QUzWzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64\n",
        "class LSTM(Module):\n",
        "    def __init__(self, n_vocab, n_hidden, n_layers):\n",
        "        self.i_h   = nn.Embedding(n_vocab, n_hidden)\n",
        "        self.rnn   = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o   = nn.Linear(n_hidden, n_vocab)\n",
        "        # We have two hidden states (h, c) that we'll keep together in state\n",
        "        self.state = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, state   = self.rnn(self.i_h(x), self.state)\n",
        "        self.state = [s.detach() for s in state] \n",
        "        return self.h_o(h)\n",
        "\n",
        "    def reset(self):\n",
        "        for s in self.state: s.zero_()"
      ],
      "metadata": {
        "id": "ZBh2Go0FzWZl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LSTM(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ],
      "metadata": {
        "id": "AwSF97cizWDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "33a566fb-e34f-46ca-d6f6-3a17d5d4bdcf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.056956</td>\n",
              "      <td>2.708244</td>\n",
              "      <td>0.341553</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.185629</td>\n",
              "      <td>1.798441</td>\n",
              "      <td>0.377360</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.627687</td>\n",
              "      <td>1.897092</td>\n",
              "      <td>0.459717</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.285119</td>\n",
              "      <td>2.024220</td>\n",
              "      <td>0.486979</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.003079</td>\n",
              "      <td>1.560079</td>\n",
              "      <td>0.567301</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.718694</td>\n",
              "      <td>1.565812</td>\n",
              "      <td>0.619303</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.469903</td>\n",
              "      <td>1.525995</td>\n",
              "      <td>0.648519</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.306789</td>\n",
              "      <td>1.473051</td>\n",
              "      <td>0.684814</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.199153</td>\n",
              "      <td>1.369004</td>\n",
              "      <td>0.728516</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.122797</td>\n",
              "      <td>1.450004</td>\n",
              "      <td>0.731364</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.075972</td>\n",
              "      <td>1.254726</td>\n",
              "      <td>0.758545</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.048235</td>\n",
              "      <td>1.323799</td>\n",
              "      <td>0.759684</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.033595</td>\n",
              "      <td>1.288537</td>\n",
              "      <td>0.757080</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>1.295729</td>\n",
              "      <td>0.759359</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.022860</td>\n",
              "      <td>1.290811</td>\n",
              "      <td>0.757406</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we reduced the chances of vanishing or exploding gradients, now we have a bit of overfitting. Although there aren't many data augmentation techniques for text (like translating to another language and then back to the original), we can apply regularization techniques like dropout, activation regularization, and temporal activation regularization. "
      ],
      "metadata": {
        "id": "x0-2iJSbWsV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Averaged SGD (ASGD) Weight-Dropped LSTM (AWD-LSTM)"
      ],
      "metadata": {
        "id": "fAS91I0_XkeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For AWD-LSTM, we need to include 4 (5) things:\n",
        "1. Dropout: randomly (through a Bernoulli trial) remove some activations with probability $p$.\n",
        "2. Activation regularization: weight decay, but with activations instead of weights.\n",
        "3. Temporal activation regularization: activation regularization, but with the difference between two consecutive activations.\n",
        "4. Weight tying: tying the hidden to output weights with the input to hidden weights. \n",
        "5. (You also use non-monotically triggered average stochastic gradient descent [(NT-ASGD)](https://arxiv.org/abs/1708.02182) as the optimizer).\n",
        "\n",
        "Dropout is where you randomly set some of the activations to zero during training to make sure all parameters are being useful in producing the output:\n",
        "\n",
        "<figure>\n",
        "    <img src='https://www.researchgate.net/publication/340700034/figure/fig3/AS:881306405724163@1587131229956/Dropout-Strategy-a-A-standard-neural-network-b-Applying-dropout-to-the-neural.ppm' alt='Dropout image'>\n",
        "    <figcaption>A neural network with 2 hidden layers. (a) Before dropout. (b) After dropout.</figcaption>\n",
        "</figure>\n",
        "\n",
        "But, we can't just zero some activations without doing something else since we won't have the same scale when we take the sum of 5 activations compared to 2 activations. So, if we have $n$ activations and apply dropout with probability $p$, then we'll have on average $(1-p)n$ activations left. Finally, we can divide them by $1-p$ to rescale the remaining to $n$, which effectively applies dropout while maintaining the scale as if we still had all activations (making dropout act like an identity function).  \n",
        "\n",
        "The PyTorch implementation of dropout is as follows:"
      ],
      "metadata": {
        "id": "ZfnsbGGtXqfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dropout(Module):\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Only apply dropout during training\n",
        "        if self.training:\n",
        "            # Creates a mask with 1s at a probability of (1-p)\n",
        "            # and 0s at a probability of p\n",
        "            mask = x.new(*x.shape).bernoulli_(1 - self.p)\n",
        "            # Divide the mask in place by (1-p) and multiply with x\n",
        "            return x * mask.div_(1 - self.p)\n",
        "        # Don't apply dropout during inference\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "BPVCgV06hZzP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply dropout before passing the outputs of our LSTM layer to the final output layer. \n",
        "\n",
        "To change the `training` attribute of a PyTorch `Module`, you can use the `train` method to set it to true and the `eval` method to set it to false. When you call these methods, it sets the `training` attribute for that `Module` and recursively applies it to the next `Module`s. You won't see it here often since it's applied automatically by fastai's `Learner` class. \n",
        "\n",
        "Activation regularization (AR) and temporal activation regularization (TAR) are essentially weight decay, but with activations. With weight decay, we add a penalty to the loss (but in practice, we add to the gradient) to make the weights as small as possible to avoid overfitting (by making the loss have less steep points). For AR and TAR, we aim to make the final LSTM activations as small as possible. \n",
        "\n",
        "With AR, we can do the following to the loss:\n",
        "\n",
        "    loss += alpha * activations.pow(2).mean()\n",
        "\n",
        "But, we know from weight decay that it'll be more efficient to add them to the gradient instead of the loss:\n",
        "\n",
        "    grad += alpha * activations.mean()\n",
        "\n",
        "Then, going straight to the gradient for TAR, we have:\n",
        "\n",
        "    grad += beta * (activation[:,1:] - activations[:,:-1]).mean()\n",
        "\n",
        "We have two new hyperparameters that we can tune for AR and TAR: `alpha` and `beta` like how we could adjust `wd` for weight decay. To apply AR and TAR, we use the `RNNRegularizer` callback ([although that class adds the square to the loss](https://github.com/fastai/fastai/blob/master/fastai/callback/rnn.py#L25)). \n",
        "\n",
        "But, to make AR and TAR work, we need our new model to return three things: (1) the actual output, (2) the LSTM activations pre-dropout and (3) the LSTM activations post-dropout. \n",
        "\n",
        "We apply AR on the post-dropout LSTM activations to not penalize the activations we dropped; and, we apply TAR on the pre-dropout LSTM activations because those dropped activations make a big difference between two consecutive time steps. \n",
        "\n",
        "Finally, we have weight tying. Weight tying is used in language models because we go from our input vocab to some hidden state, then from the hidden state to our output, which are tokens from the same vocab. So, we can expect that the mappings from input to hidden will be the same for the mapping from hidden to output; that is, the mapping is invertible (or at least, try to enforce it to be invertible). Therefore, we can set the weights of the hidden to output layer to be equal to the weights of the input to hidden layer:\n",
        "\n",
        "    self.h_o.weight = self.i_h.weight\n",
        "\n",
        "So, we now have our final model:"
      ],
      "metadata": {
        "id": "qEpTlntAjdwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AWDLSTM(Module):\n",
        "    def __init__(self, n_vocab, n_hidden, n_layers, p):\n",
        "        # What we had before in LSTM\n",
        "        self.i_h  = nn.Embedding(n_vocab, n_hidden)\n",
        "        self.rnn  = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o  = nn.Linear(n_hidden, n_vocab)\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "\n",
        "        # Dropout layer\n",
        "        self.drop = nn.Dropout(p)\n",
        "        \n",
        "        # Weight tying\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, state = self.rnn(self.i_h(x), self.h)\n",
        "        h_drop   = self.drop(h)\n",
        "        self.h   = [s.detach() for s in state]\n",
        "        return self.h_o(h_drop), h, h_drop \n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h: h.zero_()"
      ],
      "metadata": {
        "id": "e8MpZW6jmkhK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, to train this model, we have:"
      ],
      "metadata": {
        "id": "qlP6oNANqP65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, AWDLSTM(len(vocab), 64, 2, 0.5), \n",
        "                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "                cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])"
      ],
      "metadata": {
        "id": "5KRCy6mzqTKH"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, since we use those callbacks so often, we can instead use `TextLearner` which applies `ModelResetter` and `RNNRegularizer` (with `alpha=2, beta=1` as defaults):"
      ],
      "metadata": {
        "id": "SyLUg4nWqkzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = TextLearner(dls, AWDLSTM(len(vocab), 64, 2, 0.5),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ],
      "metadata": {
        "id": "_NfR01bJqwYK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, when we train our model, we can also add weight decay for additional regularization:"
      ],
      "metadata": {
        "id": "Owx9GNeZq47l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ],
      "metadata": {
        "id": "xSMFSqRlq_l1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "b8afcdfb-8967-4c32-8b6b-f717c752258c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.681149</td>\n",
              "      <td>2.038707</td>\n",
              "      <td>0.457031</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.733276</td>\n",
              "      <td>1.261145</td>\n",
              "      <td>0.619141</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.007044</td>\n",
              "      <td>0.856758</td>\n",
              "      <td>0.762370</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.523582</td>\n",
              "      <td>0.975427</td>\n",
              "      <td>0.793538</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.276582</td>\n",
              "      <td>0.704902</td>\n",
              "      <td>0.820557</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.151957</td>\n",
              "      <td>0.593644</td>\n",
              "      <td>0.867025</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.093755</td>\n",
              "      <td>0.536299</td>\n",
              "      <td>0.866455</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.061734</td>\n",
              "      <td>0.540390</td>\n",
              "      <td>0.870524</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.043401</td>\n",
              "      <td>0.519793</td>\n",
              "      <td>0.879313</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.034196</td>\n",
              "      <td>0.426708</td>\n",
              "      <td>0.882650</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.027788</td>\n",
              "      <td>0.494268</td>\n",
              "      <td>0.883626</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.023066</td>\n",
              "      <td>0.439835</td>\n",
              "      <td>0.886068</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.019279</td>\n",
              "      <td>0.433105</td>\n",
              "      <td>0.880697</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.017327</td>\n",
              "      <td>0.435248</td>\n",
              "      <td>0.886393</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.015784</td>\n",
              "      <td>0.425923</td>\n",
              "      <td>0.887614</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we've come a long ways from 49% accuracy with a single layer vanilla RNN. "
      ],
      "metadata": {
        "id": "QypaD-0qOOdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "D-9Mfl-brD9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, a recurrent neural network is just a neural network that has some layers used repeatedly such that we can put them in a loop. A vanilla RNN is fairly difficult to get a good accuracy, and, when we attempt to do a vanilla multilayer RNN, it becomes even harder to get a good accuracy because of exploding and vanishing gradients. That's why we now have LSTM (but we can also use GRU, which has only one hidden state that splits during the time step into the hidden and cell states). However, LSTM has an issue of overfitting. So, what do we do when we overfit? We apply data augmentation techniques (since we might not have enough data), but there aren't many cheap and quick data augmentation techniques for text. Instead, we opt for regularization techniques like dropout, activation regularization, temporal activation regularization, and weight tying. Applying these regularization techniques creates a new kind of architecture that we could call a rudimentary AWD-LSTM. \n",
        "\n",
        "For an actual AWD-LSTM, we have to apply dropout in a few more places:\n",
        "- Embedding dropout: inside the embeddings, drop some random rows of embeddings.\n",
        "- Input dropout: applied after the embedding layer.\n",
        "- Weight dropout: appled to the weights of LSTM after each epoch.\n",
        "- Hidden dropout: applied to the hidden state between two layers.\n",
        "\n",
        "These additional regularizations (and averaged SGD) completes AWD-LSTM, where AWD-LSTM uses 5 different kinds of dropout (the 5th is the one where we drop some activations after LSTM). There are already good defaults set in place in fastai's implementation of AWD-LSTM that we used in [this blog](https://geon-youn.github.io/DunGeon/nlp/2022/04/08/Movie-Review-Sentiment.html) and we were able to adjust the magnitude of the dropouts with the `drop_mult` parameter.  "
      ],
      "metadata": {
        "id": "TVqJ8NGxrD2f"
      }
    }
  ]
}
