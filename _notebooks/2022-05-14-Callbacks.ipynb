{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-05-14-Callbacks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \"How to use fastai's training loop Callbacks\"\n",
        "> \"Calling back, but in code.\"\n",
        "\n",
        "- comments: true\n",
        "- categories: [fastai]"
      ],
      "metadata": {
        "id": "Zm_gCBcah3iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "Y-guU1EOmgWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Last blog](https://geon-youn.github.io/DunGeon/fastai/2022/05/13/Adam.html), we used callbacks for the `Optimizer` class, which we called *optimizer callbacks*. \n",
        "\n",
        "Callbacks are pieces of code that you inject into another piece of code at some predefined point instead of directly adding to the source code. In other words, the source code is expected to call back the callback at that predefined point if that callback is passed as an argument.\n",
        "\n",
        "Injecting code is much easier than altering the source code since you won't have to copy paste the code from the library and instead can just write your own callbacks. \n",
        "\n",
        "The training loop, which looks like:\n",
        "\n",
        "```python\n",
        "for xb, yb in dl:\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "```\n",
        "\n",
        "Can be visualized like:\n",
        "\n",
        "<img height=500 src='https://github.com/fastai/fastbook/blob/master/images/att_00048.png?raw=1' alt='Training loop'>\n",
        "\n",
        "Where we can add callbacks like:\n",
        "\n",
        "<img height=500 src='https://github.com/fastai/fastbook/blob/master/images/att_00049.png?raw=1' alt='Training loop with callbacks'>\n",
        "\n",
        "Fastai is different from different libraries since they allow callbacks to be able to read, modify, and control every possible information and process available in the training loop.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wFWmdK4mi7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to create a `Callback`"
      ],
      "metadata": {
        "id": "_t5IQWR_ou92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `Callback`, unlike an optimizer callback, is for the training loop and has access to many events, which can be found as attributes through the `event` variable in case you forget. The full list can be found [here](https://docs.fast.ai/callback.core.html#Callback). \n",
        "\n",
        "In creating a callback, we can subclass `Callback`. For example, when we covered [RNNs](https://geon-youn.github.io/DunGeon/nlp/2022/04/20/Recurrent-Neural-Networks.html), we used [`ModelResetter`](https://github.com/fastai/fastai/blob/master/fastai/callback/rnn.py#L14), which we said called `reset` at the start of training and validation for each epoch. In code, it becomes:"
      ],
      "metadata": {
        "id": "mAZBysiGo1IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelResetter(Callback):\n",
        "    \"`Callback` that resets the model at each validation/training step\"\n",
        "    def before_train(self):    self.model.reset()\n",
        "    def before_validate(self): self.model.reset()\n",
        "    def after_fit(self):       self.model.reset()"
      ],
      "metadata": {
        "id": "reNExWQdquof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another example is [`RNNRegularizer`](https://github.com/fastai/fastai/blob/master/fastai/callback/rnn.py#L30), which handled activation and temporal activation regularizations:"
      ],
      "metadata": {
        "id": "Y470slXRqxe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNRegularizer(Callback):\n",
        "    \"Add AR and TAR regularization\"\n",
        "    order,run_valid = RNNCallback.order+1,False\n",
        "    def __init__(self, alpha=0., beta=0.): store_attr()\n",
        "    def after_loss(self):\n",
        "        if not self.training: return\n",
        "        if self.alpha: self.learn.loss_grad += self.alpha * self.rnn.out.float().pow(2).mean()\n",
        "        if self.beta:\n",
        "            h = self.rnn.raw_out\n",
        "            if len(h)>1: self.learn.loss_grad += self.beta * (h[:,1:] - h[:,:-1]).float().pow(2).mean()"
      ],
      "metadata": {
        "id": "N5kz-2XzqzJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Callback`s also have access to [different attributes](https://docs.fast.ai/callback.core.html#Attributes-available-to-callbacks) of `Learner`. Some of them have shortcuts when reading like `self.model` instead of `self.learn.model`, but we have to use the long form when writing; so, `self.learn.loss_grad =` instead of `self.loss_grad =`. \n",
        "\n",
        "Next, we can also use callbacks to control the training process through skipping a batch, epoch, or stop training altogether. These callbacks use [different interrupts](https://docs.fast.ai/callback.core.html#Attributes-available-to-callbacks) like `CancelBatchException` that skips the rest of the batch and goes to `after_cancel_batch` before `after_batch`.\n",
        "\n",
        "Finally, we can adjust the order of callbacks through `order` which you specify outside of function definitions in the class. For example `RNNRegularizer` will always be called after `RNNCallback` since its order is `+1` of the order of `RNNCallback`. Another example is [`TerminateOnNaNCallback`](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#L17) which has a set order of `-9`:"
      ],
      "metadata": {
        "id": "2nDtTcASxC6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TerminateOnNaNCallback(Callback):\n",
        "    \"A `Callback` that terminates training if loss is NaN.\"\n",
        "    order=-9\n",
        "    def after_batch(self):\n",
        "        \"Test if `last_loss` is NaN and interrupts training.\"\n",
        "        if torch.isinf(self.loss) or torch.isnan(self.loss): raise CancelFitException"
      ],
      "metadata": {
        "id": "RkpiPobE0osS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of `order`, which is more strict, we can also use `run_before` and `run_after` like:"
      ],
      "metadata": {
        "id": "FkufJqtA1h9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TerminateOnNaNCallback(Callback):\n",
        "    run_before=Recorder\n",
        "    def after_batch(self):\n",
        "        if torch.isinf(self.loss) or torch.isnan(self.loss): raise CancelFitException"
      ],
      "metadata": {
        "id": "1ip-ldl71lqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where, in this case, ensures that `TerminateOnNaNCallback` is executed before the `Recorder` callback."
      ],
      "metadata": {
        "id": "33yvDtrw1vH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "o8-_udcczB1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of modifying the source code, callbacks allow us to inject code in predefined points of the source code without losing flexibility (if the library allows callbacks to be flexible like fastai). We can use callbacks to read and write information in the training loop and control the flow of the training loop. "
      ],
      "metadata": {
        "id": "Fpoo0VTlzC5x"
      }
    }
  ]
}
