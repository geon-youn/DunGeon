{
  
    
        "post0": {
            "title": "Training Models on Tabular Data",
            "content": "When we train a model on tabular data, we want to create a model that, given columns, can predict the value in another column. In my collaborative filtering blog, I gave the model the user&#39;s reviews of other movies as inputs and wanted a prediction of the user&#39;s review of another movie. . Preprocessing Data . Tabular data have two main kinds of variables: continuous variables (numerical data) and categorical variables (discrete data). When training a model, we want all our inputs to be numbers In the collaborative filtering model, the users and movies were (high-cardinality) categorial variables. . So, you pass your categorical variables through embeddings. An embedding is equivalent to putting a linear layer after every one-hot-encoded input layers. What I mean is that you have inputs, which can be indexed by one-hot-encoded vectors. And, an embedding takes the relevant inputs from those inputs through indexing. In the end, when you pass your one-hot-encoded input layers through an embedding layer, you get the numerical values you need, which you can pass through other layers in your neural network. . When we train the model on these embeddings (the inputs), we can interpret the distance between the embeddings afterwards; since the embedding distances were learned based on patterns in the data, they also tend to match up with what we intuitively think they would be. . Since we can form continuous embeddings for our categorical variables, we can treat them like continuous variables when we train our models. So, we could perform probabilistic matrix factorization, or concatenate them with the actual continuous variables and pass them through a neural network. . Below demonstrates how Google trains a model for recommendations on Google Play: . And Here we Branch . In modern machine learning, there are two main techniques that are widely applicable, each good for specific kinds of data: . Ensembles of decision trees (like random forests and gradient boosting machines) for structured data. | Multilayered neural networks optimized with SGD (like shallow and/or deep learning) for unstructured data (like images, audio, and natural language). | Deep learning is almost always superior for unstructured data and give similar results for unstructured data. But, decision trees train much faster, are simpler to train, and are easier to interpret (like which columns were most important). So, ensembles of decision trees are good for forming baselines of most data. . However, deep learning is a better choice than decision trees when . there are some high-cardinality categorical variables that are very important (like zip codes); or | there&#39;s some columns that&#39;d be best understood through a neural network like plain text. | . Still, you should try both to see which one works best. Usually, you&#39;ll start with decision trees as a baseline and try to get a higher accuracy with a deep learning model if either of those two conditions above applies. . So, in the next two blog posts, I&#39;ll be talking about decision trees and deep learning, respectively, for tabular data. .",
            "url": "https://geon-youn.github.io/DunGeon/2022/03/17/Tabular.html",
            "relUrl": "/2022/03/17/Tabular.html",
            "date": " • Mar 17, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "So you want to code Collaborative Filtering",
            "content": "Hopefully you&#39;ve read my last blog post which explains everything I&#39;m going to be doing in today&#39;s blog. We&#39;re going to be coding a collaborative filtering model in two ways: by probabilistic matrix factorization and then through deep learning. If you&#39;d like to learn how deep learning works, check out my other blog post. . First, we&#39;ll download a subset of the MovieLens dataset, which contains 100,000 of the 25-million recommendation dataset. The main reason being that I&#39;m using the GPUs on Colab and it would take too long to train a model with the full dataset. . from fastai.collab import * from fastai.tabular.all import * path = untar_data(URLs.ML_100k) Path.BASE_PATH = path path.ls() . . 100.15% [4931584/4924029 00:00&lt;00:00] (#23) [Path(&#39;ua.test&#39;),Path(&#39;u.item&#39;),Path(&#39;u2.base&#39;),Path(&#39;u4.test&#39;),Path(&#39;u.user&#39;),Path(&#39;u.genre&#39;),Path(&#39;u.occupation&#39;),Path(&#39;u1.test&#39;),Path(&#39;u5.base&#39;),Path(&#39;u2.test&#39;)...] . . And we can read the README file using the cat command: . !cat {path}/README . SUMMARY &amp; USAGE LICENSE ============================================= MovieLens data sets were collected by the GroupLens Research Project at the University of Minnesota. This data set consists of: * 100,000 ratings (1-5) from 943 users on 1682 movies. * Each user has rated at least 20 movies. * Simple demographic info for the users (age, gender, occupation, zip) The data was collected through the MovieLens web site (movielens.umn.edu) during the seven-month period from September 19th, 1997 through April 22nd, 1998. This data has been cleaned up - users who had less than 20 ratings or did not have complete demographic information were removed from this data set. Detailed descriptions of the data file can be found at the end of this file. Neither the University of Minnesota nor any of the researchers involved can guarantee the correctness of the data, its suitability for any particular purpose, or the validity of results based on the use of the data set. The data set may be used for any research purposes under the following conditions: * The user may not state or imply any endorsement from the University of Minnesota or the GroupLens Research Group. * The user must acknowledge the use of the data set in publications resulting from the use of the data set (see below for citation information). * The user may not redistribute the data without separate permission. * The user may not use this information for any commercial or revenue-bearing purposes without first obtaining permission from a faculty member of the GroupLens Research Project at the University of Minnesota. If you have any further questions or comments, please contact GroupLens &lt;grouplens-info@cs.umn.edu&gt;. CITATION ============================================== To acknowledge use of the dataset in publications, please cite the following paper: F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872 ACKNOWLEDGEMENTS ============================================== Thanks to Al Borchers for cleaning up this data and writing the accompanying scripts. PUBLISHED WORK THAT HAS USED THIS DATASET ============================================== Herlocker, J., Konstan, J., Borchers, A., Riedl, J.. An Algorithmic Framework for Performing Collaborative Filtering. Proceedings of the 1999 Conference on Research and Development in Information Retrieval. Aug. 1999. FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT ============================================== The GroupLens Research Project is a research group in the Department of Computer Science and Engineering at the University of Minnesota. Members of the GroupLens Research Project are involved in many research projects related to the fields of information filtering, collaborative filtering, and recommender systems. The project is lead by professors John Riedl and Joseph Konstan. The project began to explore automated collaborative filtering in 1992, but is most well known for its world wide trial of an automated collaborative filtering system for Usenet news in 1996. The technology developed in the Usenet trial formed the base for the formation of Net Perceptions, Inc., which was founded by members of GroupLens Research. Since then the project has expanded its scope to research overall information filtering solutions, integrating in content-based methods as well as improving current collaborative filtering technology. Further information on the GroupLens Research project, including research publications, can be found at the following web site: http://www.grouplens.org/ GroupLens Research currently operates a movie recommender based on collaborative filtering: http://www.movielens.org/ DETAILED DESCRIPTIONS OF DATA FILES ============================================== Here are brief descriptions of the data. ml-data.tar.gz -- Compressed tar file. To rebuild the u data files do this: gunzip ml-data.tar.gz tar xvf ml-data.tar mku.sh u.data -- The full u data set, 100000 ratings by 943 users on 1682 items. Each user has rated at least 20 movies. Users and items are numbered consecutively from 1. The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp. The time stamps are unix seconds since 1/1/1970 UTC u.info -- The number of users, items, and ratings in the u data set. u.item -- Information about the items (movies); this is a tab separated list of movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children&#39;s | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western | The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not; movies can be in several genres at once. The movie ids are the ones used in the u.data data set. u.genre -- A list of the genres. u.user -- Demographic information about the users; this is a tab separated list of user id | age | gender | occupation | zip code The user ids are the ones used in the u.data data set. u.occupation -- A list of the occupations. u1.base -- The data sets u1.base and u1.test through u5.base and u5.test u1.test are 80%/20% splits of the u data into training and test data. u2.base Each of u1, ..., u5 have disjoint test sets; this if for u2.test 5 fold cross validation (where you repeat your experiment u3.base with each training and test set and average the results). u3.test These data sets can be generated from u.data by mku.sh. u4.base u4.test u5.base u5.test ua.base -- The data sets ua.base, ua.test, ub.base, and ub.test ua.test split the u data into a training set and a test set with ub.base exactly 10 ratings per user in the test set. The sets ub.test ua.test and ub.test are disjoint. These data sets can be generated from u.data by mku.sh. allbut.pl -- The script that generates training and test sets where all but n of a users ratings are in the training data. mku.sh -- A shell script to generate all the u data sets from u.data. . . Which tells us that u.data contains the full data set, which is 100,000 ratings by 943 users on 1682 items, where each user rated at least 20 movies. The data is tab separated with column names: user id, item/movie id, rating, and timestamp. So, let&#39;s try reading the csv: . ratings = pd.read_csv( path/&#39;u.data&#39;, delimiter = &#39; t&#39;, header = None, names = [&#39;user&#39;, &#39;movie&#39;, &#39;rating&#39;, &#39;timestamp&#39;]) ratings.head() . user movie rating timestamp . 0 196 | 242 | 3 | 881250949 | . 1 186 | 302 | 3 | 891717742 | . 2 22 | 377 | 1 | 878887116 | . 3 244 | 51 | 2 | 880606923 | . 4 166 | 346 | 1 | 886397596 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; We&#39;d like to know the actual movie name instead of the movie ID, so we can also read the u.item file (although it says it&#39;s tab separated, it&#39;s actually pipe separated): . movies = pd.read_csv( path/&#39;u.item&#39;, delimiter = &#39;|&#39;, header = None, usecols = [0, 1], names = [&#39;movie&#39;, &#39;title&#39;], encoding = &#39;latin-1&#39; ) movies.head() . movie title . 0 1 | Toy Story (1995) | . 1 2 | GoldenEye (1995) | . 2 3 | Four Rooms (1995) | . 3 4 | Get Shorty (1995) | . 4 5 | Copycat (1995) | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Then, we can merge the two tables together: . ratings = ratings.merge(movies) ratings.head() . user movie rating timestamp title . 0 196 | 242 | 3 | 881250949 | Kolya (1996) | . 1 63 | 242 | 3 | 875747190 | Kolya (1996) | . 2 226 | 242 | 5 | 883888671 | Kolya (1996) | . 3 154 | 242 | 3 | 879138235 | Kolya (1996) | . 4 306 | 242 | 5 | 876503793 | Kolya (1996) | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Then, we build our DataLoaders object, which will have our training and validation DataLoaders (which produces our mini-batches of Datasets). . dls = CollabDataLoaders.from_df(ratings, item_name = &#39;title&#39;, bs = 64) dls.show_batch() . user title rating . 0 542 | My Left Foot (1989) | 4 | . 1 422 | Event Horizon (1997) | 3 | . 2 311 | African Queen, The (1951) | 4 | . 3 595 | Face/Off (1997) | 4 | . 4 617 | Evil Dead II (1987) | 1 | . 5 158 | Jurassic Park (1993) | 5 | . 6 836 | Chasing Amy (1997) | 3 | . 7 474 | Emma (1996) | 3 | . 8 466 | Jackie Chan&#39;s First Strike (1996) | 3 | . 9 554 | Scream (1996) | 3 | . And then we create our model, which will contain our embeddings. We can&#39;t just index into a matrix for a deep learning model since we have to calculate the derivative for each operation we do. Instead, we use one-hot encoding, which is a vector that has a 1 in the places that we want to index in. For example, if we have an array [0, 1, 2, 3] and we want the element in the 2nd index (2), we would matrix multiply [0, 0, 1, 0] to the array&#39;s transpose: $$ begin{bmatrix}0 &amp; 1 &amp; 2 &amp; 3 end{bmatrix}^T begin{bmatrix}0&amp;0&amp;1&amp;0 end{bmatrix}= begin{bmatrix}0 1 2 3 end{bmatrix} begin{bmatrix}0&amp;0&amp;1&amp;0 end{bmatrix}= begin{bmatrix}2 end{bmatrix}$$ . But, storing and using one-hot encoding vectors are pretty time and memory consuming, so we use a special layer in most deep learning libraries (like PyTorch) called embedding. Embedding is mimicking the process of multiplying by a one-hot-encoded matrix, but it just indexes into a matrix using an integer while having its derivative calculated in a way such that it&#39;s identical to what it would&#39;ve been if a matrix multiplication was done with a one-hot-encoded vector. . Optimizers need to be able to get all the parameters from a model, so all embedding does is randomly initialize a matrix and wrap it around the nn.Parameter class which tells PyTorch that it&#39;s a trainable parameter. . When we refer to an embedding, that&#39;s the embedding matrix, which is the thing that&#39;s multiplied by the one-hot-encoded matrix or the thing that&#39;s being indexed into. So, an embedding matrix in this case, is our latent factors (and biases). . When creating a neural network model with PyTorch, we have to inherit from their Module class which contains the essentials; we just have to define __init__ (called dunder init) to initialize our model and forward which is essentially the &quot;predict&quot; step in the model. forward accepts the parameters of a mini-batch and returns a prediction. . n_users = len(dls.classes[&#39;user&#39;]) n_items = len(dls.classes[&#39;title&#39;]) n_factors = 50 . class DotProduct(Module): def __init__(self, n_users, n_items, n_factors, y_range = (0, 5.5)): # User latent factors and biases self.user_factors = Embedding(n_users, n_factors) self.user_bias = Embedding(n_users, 1) # Item latent factors and biases self.item_factors = Embedding(n_items, n_factors) self.item_bias = Embedding(n_items, 1) # Range for our predictions self.y_range = y_range def forward(self, x): # Get first column (the users) from input users = self.user_factors(x[:,0]) # Get second column (the titles) from input items = self.item_factors(x[:,1]) # Calculate the dot product dot_prod = (users * items).sum(dim = 1, keepdim = True) # Add biases to the dot product # We add the user biases and the item biases together dot_prod += self.user_bias(x[:,0]) + self.item_bias(x[:,1]) # Return the prediction in the chosen range # Sigmoid is a function that returns a value between 0 and 1 # We can multiply it by (hi - lo) and add lo to get a value # between lo and hi, which is what sigmoid_range does return sigmoid_range(dot_prod, *self.y_range) . Now that we have our model, we can create an object with it and pass it into a Learner and train it. . model = DotProduct(n_users, n_items, n_factors) learn = Learner(dls, model, loss_func = MSELossFlat()) # We also use weight decay since we have bias in our model learn.fit_one_cycle(5, 5e-3, wd = 0.1) . epoch train_loss valid_loss time . 0 | 0.941400 | 0.941900 | 00:09 | . 1 | 0.847874 | 0.877467 | 00:08 | . 2 | 0.719121 | 0.835374 | 00:07 | . 3 | 0.594287 | 0.824023 | 00:07 | . 4 | 0.483335 | 0.824634 | 00:07 | . And, we don&#39;t need to define our own DotProduct class. We can instead use fast.ai&#39;s collab_learner. . learn = collab_learner(dls, n_factors = 50, y_range = (0, 5.5)) learn.fit_one_cycle(5, 5e-3, wd = 0.1) . epoch train_loss valid_loss time . 0 | 0.940803 | 0.954099 | 00:08 | . 1 | 0.846296 | 0.874175 | 00:07 | . 2 | 0.741423 | 0.838990 | 00:07 | . 3 | 0.590897 | 0.822672 | 00:07 | . 4 | 0.492853 | 0.823269 | 00:07 | . And we see the results are similar since the model used by collab_learner is essentially equivalent: . # 50 latent factors for users and items # bias for users and items learn.model . EmbeddingDotBias( (u_weight): Embedding(944, 50) (i_weight): Embedding(1665, 50) (u_bias): Embedding(944, 1) (i_bias): Embedding(1665, 1) ) . To turn our architecture into a deep learning model, we need a neural network. With a neural network, we start with a large matrix that we pass through layers. Instead of taking the dot product, we concatenate the latent factors from the users and the items. So, we also don&#39;t need the same number of latent factors for users as for items. To get the number of latent factors, we can use fast.ai&#39;s get_emb_sz function on our DataLoaders, which will give us recommended latent factors: . embs = get_emb_sz(dls) embs . [(944, 74), (1665, 102)] . And, we can rewrite our DotProduct class like so: . class SimpleNet(Module): def __init__(self, user_sz, item_sz, y_range = (0, 5.5), n_acts = 100): # nn.Linear implements bias implicitly, so we # don&#39;t need to define our own bias. self.user_factors = Embedding(*user_sz) self.item_factors = Embedding(*item_sz) self.layers = nn.Sequential( nn.Linear(user_sz[1] + item_sz[1], n_acts), nn.ReLU(), nn.Linear(n_acts, 1)) self.y_range = y_range def forward(self, x): embs = self.user_factors(x[:,0]),self.item_factors(x[:,1]) x = self.layers(torch.cat(embs, dim = 1)) return sigmoid_range(x, *self.y_range) . Then, we can put it in a Learner and train our deep learning model: . model = SimpleNet(*embs) learn = Learner(dls, model, loss_func = MSELossFlat()) learn.fit_one_cycle(5, 5e-3, wd = 0.1) . epoch train_loss valid_loss time . 0 | 0.942289 | 0.957183 | 00:07 | . 1 | 0.918996 | 0.915120 | 00:07 | . 2 | 0.854367 | 0.902296 | 00:07 | . 3 | 0.820374 | 0.877131 | 00:07 | . 4 | 0.827481 | 0.877810 | 00:07 | . And, like how we didn&#39;t need to define our own DotProduct class and use collab_learner instead, we can also do the same with SimpleNet. . # We just have to enable the use_nn parameter and # give it layers learn = collab_learner(dls, use_nn = True, y_range = (0, 5.5), layers = [100, 50]) learn.fit_one_cycle(5, 5e-3, wd = 0.1) . epoch train_loss valid_loss time . 0 | 1.018050 | 0.979968 | 00:13 | . 1 | 0.906580 | 0.922872 | 00:08 | . 2 | 0.909671 | 0.890887 | 00:08 | . 3 | 0.814160 | 0.870163 | 00:08 | . 4 | 0.802491 | 0.869587 | 00:09 | . So you want to interpret the results . Now that you&#39;ve trained a model, there&#39;s several ways to interpret your results. . First, we can look at the biases: . # First, take the biases and put them into # a one-dimensional tensor that we can sort item_bias = learn.model.item_bias.weight.squeeze() # argsort returns a list of indexes that would # sort the tensor idxs_bot = item_bias.argsort()[:5] idxs_top = item_bias.argsort(descending = True)[:5] # display the titles of the 5 &quot;worst&quot; movies # and the 5 &quot;best&quot; movies, respectively [dls.classes[&#39;title&#39;][i] for i in idxs_bot],[dls.classes[&#39;title&#39;][i] for i in idxs_top] . ([&#39;Children of the Corn: The Gathering (1996)&#39;, &#39;Lawnmower Man 2: Beyond Cyberspace (1996)&#39;, &#39;Crow: City of Angels, The (1996)&#39;, &#39;Beautician and the Beast, The (1997)&#39;, &#39;Robocop 3 (1993)&#39;], [&#39;Titanic (1997)&#39;, &#39;L.A. Confidential (1997)&#39;, &#39;Shawshank Redemption, The (1994)&#39;, &#34;Schindler&#39;s List (1993)&#34;, &#39;Silence of the Lambs, The (1991)&#39;]) . Then, we can find the distances: . item_factors = learn.model.item_factors.weight idx = dls.classes[&#39;title&#39;].o2i[&#39;Toy Story (1995)&#39;] distances = nn.CosineSimilarity()(item_factors, item_factors[idx][None]) idx = distances.argsort(descending = True)[1:5] dls.classes[&#39;title&#39;][idx] . (#4) [&#39;That Thing You Do! (1996)&#39;,&#39;Abyss, The (1989)&#39;,&#39;Wizard of Oz, The (1939)&#39;,&#39;Aladdin (1992)&#39;] . So, the four movies in the data set that are most similar to Toy Story are the ones above. . In the next few blogs, I&#39;ll be talking more about deep and machine learning with tabular data. .",
            "url": "https://geon-youn.github.io/DunGeon/2022/03/16/Collab.html",
            "relUrl": "/2022/03/16/Collab.html",
            "date": " • Mar 16, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "So you want to learn Collaborative Filtering",
            "content": "What is Collaborative Filtering . You want to start a movie streaming service. You&#39;re learning machine learning and you want a way to recommend people movies so they watch more and spend more time on your app so you get more ad revenue. How would you solve this problem? . Let&#39;s look at Bingus. He&#39;s a McMaster alumni turned McDonald&#39;s employee. He works an 8 AM to 6 PM shift flipping burgers for minimum wage and gets home to watch some movies. He really likes this one movie called &quot;Cars 3&quot;. He&#39;s watched dozens of times now and he won&#39;t stop. . Then comes Alice. Unlike Bingus, she graduated from Waterloo and landed a CS job earning six figures. She even graduated with the highest GPA of her year and landed that CS job through a return offer from her summer coop. So what? Alice and Bingus both like &quot;Cars 3&quot;. . Since they both like &quot;Cars 3&quot;, we could recommend Alice movies that Bingus also likes and recommend Bingus movies that Alice also likes. . . Collaborative filtering: look at items the current user used or liked, find other users that used or liked similar items, then recommend those items to the current user. . . Collaborative filtering works through latent factors, which are basically the &quot;tags&quot; you would give an item. For example, you could give a movie tags like &quot;science fiction,&quot; &quot;action,&quot; &quot;old,&quot; &quot;horror,&quot; and &quot;romance.&quot; It&#39;s latent because it depends on users for the factors to have meaning. . What&#39;s wild is we never tell our model the latent factors. We just say how many we want and the model learns them on its own. So, we don&#39;t need to know anything about the items (in a descriptive way); we just need the data on the users and the items. . How to implement Collaborative Filtering . Our model will work using stochastic gradient descent. So, we need three things: . random parameters; | a way to calculate our predictions; and | a loss function. | . We first randomly initialize some parameters for our latent factors. Let&#39;s say we want our model to learn 5 latent factors. Then, each user and item would have 5 parameters (or, a 5-dimensional vector). We can use the dot product between the user and the item as our prediction of how likely we would recommend an item to a user. The higher the value, the more likely the user will like that product. . Finally, we need to pick a loss function. Since we&#39;re dealing with regression instead of classification (like digit classification), we can use L1 norm or L2 norm. . . L1 norm (absolute mean difference): take the absolute difference between two values and take the mean. . $$L_1= sum^n_{i=0} frac{|a_i-b_i|}{2}, ,a in A, , b in B$$ . L2 norm (root mean squared error): take the square of the differences between two values and take the mean. Then, square root the result. $$L_2= sqrt{ sum^n_{i=0} frac{(a_i-b_i)^2}{2}}, ,a in A, , b in B$$ . . What&#39;s the difference? L2 norm puts a larger emphasis on small and large changes because of squaring since large * large = larger and small * small = smaller. . Now, we have all we need for stochastic gradient descent: random parameters, a way to calculate our predictions, and our loss function. . At each step, the SGD optimizer calculates the match between each item and user (random parameters) using the dot product (procedure for predictions), and compares it to the actual rating that each user gave to each item (loss function). Then, it calculates the derivative of this value (gradient) and steps the weights by multiplying the calculated derivative by the learning rate and subtracting the weights by that value (descent). . After each epoch, the loss gets better (lower) and the recommendations will also get better. . But something&#39;s missing... . There&#39;s usually a range for ratings on an item. Like &quot;out of 5 stars&quot;. So, you should put a range on your predictions so that they&#39;re in a similar range as the rating system you have for an item. For example, if a movie service has a rating system from 0 to 5, you should have a range from 0 to 5.5. It&#39;s been discovered empirically that having the upper bound a little bit over returns better results. . And, remember how parameters are the weights and biases? We should also have biases attached to each user and each item. Some users may be more positive or negative than others. And, some items may be superior than others. It could also reflect current trends. Nonetheless, adding biases on their own usually leads to overfitting. . So, you also need to add L2 regularization, . . L2 regularization (weight decay): add the sum of all the weights squared to your loss function. . . Why? Because when you compute the gradients, the added sum encourages the weights to be as small as possible. It prevents overfitting because having high parameters lead to sharper changes in the loss function, which can lead to overfitting. So, having smaller parameters encouraged by weight decay decreases that. . However, you don&#39;t apply weight decay by adding the sum of all weights squared to the loss function (it would be inefficient and lead to huge numbers). Instead, add double the parameters to the gradient since the derivative of $x^2$ is $2x$. And, weight decay is just a hyperparameter that you multiply $2x$ by, so what you actually do is gradient += wd * 2 * parameters, which is essentially gradient += wd * parameters (2 is incorporated into wd like how you just have + C for integrals). The end result of adding biases with weight decay is that we make training the model a bit harder, but the model will generalize better in practice. . Interpreting the model . Now, you finished training your model. You have your biases and latent factors (weights) all set. How can you interpret your parameters before putting your model in action? . With biases, you can sort items to see . current trends; and | which items are good (high bias) or bad (low bias). | . Interpreting the latent factors is a bit trickier in that you can&#39;t just model it. But, there is a technique called principal component analysis, which lets you take the most important directions in the latent factors. . There&#39;s a simpler alternative if you just want to compare a few items: you can calculate the &quot;distance&quot; between two items. If two items were very similar, then their latent factors would also be similar. So, their &quot;distance&quot; would be low compared to the distance between a more different item. Ultimately, item similarity in a model is dictated by the similarity of users that like those items. . To calculate to distance, you use Pythagoras&#39; formula: . $$d= sqrt{(x_2-x_1)^2+(y_2-y_1)^2}$$ . except you would do this for how many dimensions there are. For example, the distance between two 50-dimensional embedding (the parameters) would be . $$d= sqrt{(x_{2,1}-x_{1,1})^2+(x_{2,2}-x_{1,2})^2+ dots+(x_{2,50}-x_{1,50})^2}$$ . So, say you have one movie, &quot;Cars 3&quot; and two other movies: &quot;Cars 4&quot; and &quot;Harry Potter&quot;. The distance between &quot;Cars 3&quot; and &quot;Cars 4&quot; might be 50, while it&#39;s 100 for &quot;Cars 3&quot; and &quot;Harry Potter&quot;. Then, since the distance for the former is shorter, you could infer that &quot;Cars 3&quot; is more similar to &quot;Cars 4&quot; than &quot;Cars 3&quot; is to &quot;Harry Potter&quot;. . But wait, there&#39;s a problem . We all know by now that overfitting is a big problem in the training process. But, there&#39;s an equally important problem in practice for collaborative filtering: the bootstrapping problem. . . Bootstrap: to start something with little help. . Bootstrapping problem: what do you do when you have no users (no data) to train your model; and, if you do have previous users, what do you recommend for a new user? Similarly, what do you do when you add a new item? . . Like overfitting, there isn&#39;t a solution that works for everything, but there are some used commonly: . assign the mean/median of all the latent factors to the new user or item; | pick a specific user or item to represent the average user; | survey the new user or item to construct a basic set of latent factors for them. | . However, solutions to the bootstrapping problem leads to another problem: positive feedback loops. A small number of otakus can set the recommendation for the entire user base. You might expect this feedback loop to be an outlier, but it&#39;s actually the norm. For example, even though not a lot of people watch anime, a few people really enjoy &quot;Demon Slayer&quot;; so when the movie came out, it became highly recommended for the general user base. Similarly, &quot;Squid Game&quot; also became popular this way along with many Korean movies like &quot;Parasite&quot; and &quot;Train to Busan&quot;. It&#39;s only when the systems do something about it (like deliberately lower its bias, don&#39;t recommend it anymore, or through time) that the feedback loop stops. . The bias for certain items in the latent factors may be due to representation bias. If you don&#39;t want your entire user base (and your system) to change, then you have to be wary of these feedback loops. Once the bias becomes too high, more people of the same group come along and your user base ends up being that group. . An easy way to prepare for feedback loops is to integrate your model slowly: . first, have people monitor the model and its recommendations; | then, monitor the recommendations over time; and | eventually let the model recommend on its own. | . So you want to do Deep Learning . Our first method isn&#39;t deep learning, but instead called probabilistic matrix factorization. Instead of a neural network, we used the dot product to calculate our predictions. . With deep learning, we need a neural network, which contains all the layers with parameters that we optimize in each epoch. So, we also don&#39;t need the same number of latent factors for items and users since we won&#39;t be using the dot product. . What you&#39;ll find is that deep learning is a bit worse than probabilistic matrix factorization on its own. But, you can add other user and item information, date and time information, and/or any other information that might be relevant to the recommendation. .",
            "url": "https://geon-youn.github.io/DunGeon/2022/03/12/Collaborative-Filtering.html",
            "relUrl": "/2022/03/12/Collaborative-Filtering.html",
            "date": " • Mar 12, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "So, What is Deep Learning?",
            "content": "So what is deep learning? From what I&#39;ve seen so far of the fast.ai course (chapters 1 to 7), deep learning is training a model with labelled data such that it is able to predict labels for unlabelled data in practice. . With a standard algorithm, you get inputs, you give it to the algorithm, and you get an output; you know the code in the algorithm (or at least, you should understand it). It&#39;s similar in a deep learning model: you know how the model is going to be trained (by hyperparameters like loss function, architecture like resnet18, optimizer like SGD, number of epochs, etc.) and you can look into the parameters (what the model learned; e.g., in vision models you can look at the layers and see how the earlier layers learn things like edges, gradients, etc. while the later layers learn more of the complex things like dog faces). . The difference is that you didn&#39;t hard code the parameters - hopefully - like how you hard coded the algorithm (or copied from a library or Stack Overflow). You have to train the model by giving it labelled data. Emphasis on labelled data. The model can&#39;t learn if it doesn&#39;t have anything to learn from. Why? Because you&#39;re creating a model to predict labels so your data should be labelled. So, a lot of deep learning ends up just labelling your data correctly (or labelling your data in general). . Then, there&#39;s overfitting - an obstacle that prevents your model from being useful. Imagine this: your model predicts your training data with near 100% accuracy. Congrats! You should get an award! Oh, wait, your model can only predict the validation set with 90% accuracy. Oh, double wait, your model can only predict the test set with 50% accuracy... WHAT&#39;S HAPPENING? Your model is memorizing (over-fitting) your training data instead of actually learning from it. . So, you should be careful when training your model. There&#39;s so many options you can tune when training a model. From what I&#39;ve seen so far, you usually overfit by . having a large number of epochs, | using too large or small learning rate, | having a poorly split dataset (like having a random split on a time series data), and | making some post-training decisions that you end up overfitting on the validation set, and | not using a pre-trained model (if one exists for your intentions). | . Remember, you want your model to be good at generalizing on previously unseen data... unless you have a dataset that&#39;s so large that there is no previously unseen data. It doesn&#39;t matter how well your model does on your training and validation sets if it doesn&#39;t work with the test set or a random piece of data you give it! . Then, What is a Deep Learning Model? . A deep learning model consists of layers. Remember how I mentioned resnet18? That&#39;s an architecture (pre-trained too, which means it&#39;s been trained on a dataset before and we&#39;re retraining it with our own dataset which saves time and money since we&#39;ll start with a pretty high accuracy). An architecture is the skeleton of a deep learning model. It contains all the layers and parameters. resnet18 as you could assume, contains 18 layers. . A layer is technically composed of two things. The first is a linear layer ($w cdot x+b$, where $w$ are the weights, $x$ is the data or input, and $b$ is the bias; what people call the parameters of a model is the weights and biases) followed by a non-linear layer typically a ReLU (rectified linear unit, which turns all negative numbers to 0 and keeps positive numbers as is). So, you may be wondering: why do we need both? Well, if you only had linear layers, you could combine all of them into a single layer. So, we need some kind of nonlinearity so that we can prevent the linear layers from becoming one big linear layer. . Now, lets say you have an image. We transform the data, for example through resizing and augmenting it (sort of like distorting it, but in a good way), such that it&#39;s $224 times 224$ pixels large. That&#39;s $50176$ pixels. Then, there could be $4$ more categories for red, green, blue, and alpha (transparency). That becomes $200704$ input values for the first layer. With each layer, you want to decrease that value until the last layer, where you&#39;ll have $n$ outputs since you have $n$ different labels. . Then, how does the model actually learn? Every time you pass a piece of data and you get a prediction, that prediction is passed onto a function called the loss function (what you care about is the metric function, the computer cares about the loss function), using that loss function, each parameter takes a step in the opposite direction of the slope of that loss function at that paramter&#39;s value such that by the next prediction, the value of the loss function is smaller. How big is that step? It&#39;s determined by the learning rate you chose. That&#39;s why it&#39;s important to have a good loss function and a reasonable learning rate. . And, you may be saying, &quot;that&#39;s cool and all, but how does that step actually work?&quot; Each number in a layer (weights and biases) are set so that they keep track of what functions are applied to them. So, when you take a &quot;step&quot; (or optimize; hence, &quot;optimizer&quot; like SGD), you first calculate the function of the derivates of the functions applied through chain rule and takes the value of that gradient (so if the derivative is $f&#39;$ and the number is $x$, the value would be $f&#39;(x)$). Then, with the learning rate, you take a step in the opposite direction such that you descend (parameters -= gradient * learning_rate). Now you can guess why they called the process &quot;stochastic gradient descent.&quot; You descend the loss function (which should be easily differentiable and typically have non-zero gradients) based on the gradient and the parameters are usually randomly assigned, hence &quot;stochastic.&quot; . With each epoch (which is one complete pass through the data), the parameters are finetuned for your task, eventually memorizing the training set. You don&#39;t want that, so you train it for as few epochs as you need (to prevent overfitting and to save time). . Remember when I said &quot;you care about the metric function?&quot; That&#39;s what you want to pay attention to after each epoch. Metric functions are typically things like accuracy or error rate (which is 1 - accuracy), which are helpful for us to analyze our model, but terrible for our model to use as loss functions. . With an overfitting model, you usually see two things: the loss for the training set continues to decrease, but the loss for the validation set is suddenly increasing. The opposite is true for the metric: the metric for the training set is increasing, but the metric for the validation set is decreasing. That&#39;s why you typically want a test set. A training set is the set your model sees when it&#39;s training. A validation set is for your eyes only and used to test how well the model is learning. A test set is for no one&#39;s eyes. Only for God&#39;s eyes or whatever you believe in. Once you finished training your model and tuned all the hyperparameters you want, a test set will tell you how well your model actually trained. . Of course, the validation set and training set are going to be useless if you split your data badly. The common example is with a time series dataset. If you split your data randomly, the model can easily predict intermediate values, but why would you want to know about the past? You want to predict the future. So, you could have your training set consist of data not containing the most recent 6 months, for example. And your validation set consists of the remaining 6 months. You could even take the most recent month out and put the first 5 months into your validation set instead and the most recent month into the test set. Whenever you split your data, make sure it&#39;s with the intention that the model will be learning the patterns of the data such that it can generalize to future, never-seen-before data. . That&#39;s it? . Well, that&#39;s basically what I got so far from fast.ai. With Arthur Samuel&#39;s definition of deep learning, you essentially have a model, where you give it labelled data as input, it produces predictions, then those predictions are passed to a loss function, then you optimize the predictions and repeat for $n$ many epochs until you reach a certain point and stop training the model. . There are many parts that you can change in a model with some that you have to change depending on the task, particularly the loss function. . I&#39;ve mainly been focusing on computer vision since that&#39;s what the first 7 chapters were about (apart from chapter 1; I&#39;m also leaving chapter 3 for last, which is about ethics). . Next time you see me, I&#39;ll be talking about tabular data. .",
            "url": "https://geon-youn.github.io/DunGeon/2022/03/07/What-Is-Deep-Learning.html",
            "relUrl": "/2022/03/07/What-Is-Deep-Learning.html",
            "date": " • Mar 7, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "A Classifier on Pet Breeds",
            "content": "Intro . I remember volunteering at a hackathon and sitting in the award ceremony when I saw a group win in the &quot;fun&quot; category for creating a pet breed classifier. You give it an image and it&#39;ll tell you what breed it thinks it is and how confident it is. It was &quot;fun&quot; because you could override the threshold and allow images that aren&#39;t cats and dogs to be classified as a dog or cat breed. This blog post will show you how you can train your own pet breed classifer and how it isn&#39;t that hard nor time consuming to do so. You don&#39;t need a beefy computer either since you can use Colab&#39;s GPUs. . Training Our Own Pet Breed Classifier . First, we&#39;ll download the Pet dataset and see what we&#39;re given: . path = untar_data(URLs.PETS) Path.BASE_PATH = path . path.ls() . (#2) [Path(&#39;images&#39;),Path(&#39;annotations&#39;)] . (path/&#39;images&#39;).ls() . (#7393) [Path(&#39;images/english_setter_69.jpg&#39;),Path(&#39;images/scottish_terrier_120.jpg&#39;),Path(&#39;images/basset_hound_113.jpg&#39;),Path(&#39;images/miniature_pinscher_87.jpg&#39;),Path(&#39;images/pomeranian_1.jpg&#39;),Path(&#39;images/Persian_68.jpg&#39;),Path(&#39;images/japanese_chin_39.jpg&#39;),Path(&#39;images/english_setter_107.jpg&#39;),Path(&#39;images/Birman_128.jpg&#39;),Path(&#39;images/staffordshire_bull_terrier_26.jpg&#39;)...] . In this dataset, there are two subfolders: images and annotations. images contains the images of the pet breeds (and their labels) while annotations contains the location of the pet in each image if you wanted to do localization. . The images are structured like so: the name of the pet breed with spaces turned into underscores, followed by a number. The name is capitalized if the pet is a cat. We can get the name of the pet breed by using regular expressions: . fname = (path/&#39;images&#39;).ls()[0] fname, fname.name . (Path(&#39;images/english_setter_69.jpg&#39;), &#39;english_setter_69.jpg&#39;) . # () = extract what&#39;s in the parentheses -&gt; .+ # .+ = any character appearing one or more times # _ = followed by an underscore # d+ = followed by any digit appearing one or more times # .jpg$ = with a .jpg extension at the end of the string re.findall(r&#39;(.+)_ d+.jpg$&#39;, fname.name) . [&#39;english_setter&#39;] . This time, we&#39;ll be using a DataBlock to create our DataLoaders . pets = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = partial(get_image_files, folders = &#39;images&#39;), splitter = RandomSplitter(), get_y = using_attr(RegexLabeller(r&#39;(.+)_ d+.jpg$&#39;), &#39;name&#39;), item_tfms = Resize(460), batch_tfms = aug_transforms(size = 224, min_scale = 0.75)) dls = pets.dataloaders(path) . In our pets DataBlock, we give it the following parameters: . blocks = (ImageBlock, CategoryBlock): our independent variable is an image and our dependent variable is a category. | get_items = partial(get_image_files, folders = &#39;images&#39;): we are getting our images recursively in the images folder. If you&#39;ve used functional programming before, partial is like currying; we give a function some of its parameters and it returns another function that accepts the rest of its parameters, except partial allows us to specify which parameters we want to give. | splitter = RandomSplitter(): randomly splits our data into training and validation sets with a default 80:20 split. We can also specify a seed if we want to test how tuning our hyperparameters affects the final accuracy. | . The final two parameters are part of &quot;presizing&quot;: . item_tfms = Resize(460): picks a random area of an image (using its max width or height, whichever is smallest) and resizes it to 460x460. This process happens for all images in the dataset. | batch_tfms = aug_transforms(size = 224, min_scale = 0.75): take a random portion of the image which is at least 75% of it and resize to 224x224. This process happens for all images in a batch (like the batch we get when we call dls.one_batch()). | . We first resize an image to a much larger size than our actual size for training so that we can avoid the data destruction done by data augmentation. The larger size allows tranformation of the data without creating empty areas. . . We can check if our DataLoaders is created successfully by using the .show_batch() feature: . dls.show_batch(nrows = 1, ncols = 4) . We can then do some Googling to make sure our images are labelled correctly. . Fastai also allows us to debug our DataBlock in case we make an error. It attemps to create a batch from the source: . pets.summary(path) . Setting-up type transforms pipelines Collecting items from /root/.fastai/data/oxford-iiit-pet Found 7390 items 2 datasets of sizes 5912,1478 Setting up Pipeline: PILBase.create Setting up Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} Building one sample Pipeline: PILBase.create starting from /root/.fastai/data/oxford-iiit-pet/images/great_pyrenees_179.jpg applying PILBase.create gives PILImage mode=RGB size=500x334 Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} starting from /root/.fastai/data/oxford-iiit-pet/images/great_pyrenees_179.jpg applying partial gives great_pyrenees applying Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} gives TensorCategory(21) Final sample: (PILImage mode=RGB size=500x334, TensorCategory(21)) Collecting items from /root/.fastai/data/oxford-iiit-pet Found 7390 items 2 datasets of sizes 5912,1478 Setting up Pipeline: PILBase.create Setting up Pipeline: partial -&gt; Categorize -- {&#39;vocab&#39;: None, &#39;sort&#39;: True, &#39;add_na&#39;: False} Setting up after_item: Pipeline: Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor Setting up before_batch: Pipeline: Setting up after_batch: Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} -&gt; Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} -&gt; RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;p&#39;: 1.0} -&gt; Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False} Building one batch Applying item_tfms to the first sample: Pipeline: Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} -&gt; ToTensor starting from (PILImage mode=RGB size=500x334, TensorCategory(21)) applying Resize -- {&#39;size&#39;: (460, 460), &#39;method&#39;: &#39;crop&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;resamples&#39;: (2, 0), &#39;p&#39;: 1.0} gives (PILImage mode=RGB size=460x460, TensorCategory(21)) applying ToTensor gives (TensorImage of size 3x460x460, TensorCategory(21)) Adding the next 3 samples No before_batch transform to apply Collating items in a batch Applying batch_tfms to the batch built Pipeline: IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} -&gt; Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} -&gt; RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;p&#39;: 1.0} -&gt; Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False} starting from (TensorImage of size 4x3x460x460, TensorCategory([21, 30, 15, 2], device=&#39;cuda:0&#39;)) applying IntToFloatTensor -- {&#39;div&#39;: 255.0, &#39;div_mask&#39;: 1} gives (TensorImage of size 4x3x460x460, TensorCategory([21, 30, 15, 2], device=&#39;cuda:0&#39;)) applying Flip -- {&#39;size&#39;: None, &#39;mode&#39;: &#39;bilinear&#39;, &#39;pad_mode&#39;: &#39;reflection&#39;, &#39;mode_mask&#39;: &#39;nearest&#39;, &#39;align_corners&#39;: True, &#39;p&#39;: 0.5} gives (TensorImage of size 4x3x460x460, TensorCategory([21, 30, 15, 2], device=&#39;cuda:0&#39;)) applying RandomResizedCropGPU -- {&#39;size&#39;: (224, 224), &#39;min_scale&#39;: 0.75, &#39;ratio&#39;: (1, 1), &#39;mode&#39;: &#39;bilinear&#39;, &#39;valid_scale&#39;: 1.0, &#39;max_scale&#39;: 1.0, &#39;p&#39;: 1.0} gives (TensorImage of size 4x3x224x224, TensorCategory([21, 30, 15, 2], device=&#39;cuda:0&#39;)) applying Brightness -- {&#39;max_lighting&#39;: 0.2, &#39;p&#39;: 1.0, &#39;draw&#39;: None, &#39;batch&#39;: False} gives (TensorImage of size 4x3x224x224, TensorCategory([21, 30, 15, 2], device=&#39;cuda:0&#39;)) . . Now, let&#39;s get to training our model. This time, we&#39;ll be fine tuning a pretrained model. This process is called transfer learning, where we take a pretrained model and retrain it on our data so that it can perform well for our task. We randomize the head (last layer) of our model, freeze the parameters of the earlier layers and train our model for one epoch. Then, we unfreeze the model and update the later layers of the model with a higher learning rate than the earlier layers. . The pretrained model we will be using is resnet34, which was trained on the ImageNet dataset with 34 layers: . learner = cnn_learner(dls, resnet34, metrics = accuracy) . lrs = learner.lr_find() . learner.fit_one_cycle(3, lr_max = lrs.valley) . epoch train_loss valid_loss accuracy time . 0 | 1.542125 | 0.296727 | 0.900541 | 01:14 | . 1 | 0.618474 | 0.227452 | 0.924222 | 01:13 | . 2 | 0.401809 | 0.214500 | 0.932341 | 01:12 | . learner.unfreeze() lrs = learner.lr_find() . learner.fit_one_cycle(6, lr_max = lrs.valley) . epoch train_loss valid_loss accuracy time . 0 | 0.340459 | 0.213287 | 0.928281 | 01:16 | . 1 | 0.341917 | 0.233392 | 0.921516 | 01:16 | . 2 | 0.277254 | 0.187060 | 0.939107 | 01:16 | . 3 | 0.191343 | 0.192029 | 0.938430 | 01:16 | . 4 | 0.156336 | 0.178532 | 0.941813 | 01:16 | . 5 | 0.123608 | 0.174198 | 0.939107 | 01:16 | . When we use a pretrained model, fastai automatically freezes the early layers.We then train the head (last layer) of the model for 3 epochs so that it can get a sense of our objective. Then, we unfreeze the model and train all the layers for 6 more epochs. After training for a total of 9 epochs, we now have a model that can predict pet breeds accuractely 94% of the time. We can use fastai&#39;s confusion matrix to see where our model is having problems: . interp = ClassificationInterpretation.from_learner(learner) interp.plot_confusion_matrix(figsize = (12, 12), dpi = 60) . interp.most_confused(5) . [(&#39;staffordshire_bull_terrier&#39;, &#39;american_pit_bull_terrier&#39;, 6), (&#39;Ragdoll&#39;, &#39;Birman&#39;, 5), (&#39;chihuahua&#39;, &#39;miniature_pinscher&#39;, 5)] . Using the .most_confused feature, it seems like most of the errors come from the pet breeds being very similar. We should be careful however, that we aren&#39;t overfitting on our validation set through changing hyperparameters. We can see that our training loss is always going down, but our validation loss fluctuates from going down and sometimes up. . And that&#39;s all there is to training a pet breed classifier. You could improve the accuracy by exploring deeper models like resnet50 which has 50 layers; training for more epochs (whether before unfreezing or after or both); using discriminative learning rates (giving lower learning rates or early laters using split(lr1, lr2) in the lr_max key-word argument in fit_one_cycle). . Using Our Own Pet Breed Classifier . First, let&#39;s save the model using .export(): . learner.export() . Then, let&#39;s load the .pkl file: . learn = load_learner(&#39;export.pkl&#39;) . Create some basic UI: . def pretty(name: str) -&gt; str: return name.replace(&#39;_&#39;, &#39; &#39;).lower() . def classify(a): if not btn_upload.data: lbl_pred.value = &#39;Please upload an image.&#39; return img = PILImage.create(btn_upload.data[-1]) pred, pred_idx, probs = learn.predict(img) out_pl.clear_output() with out_pl: display(img.to_thumb(128, 128)) lbl_pred.value = f&#39;Looks like a {pretty(pred)} to me. I &#39;m {probs[pred_idx] * 100:.02f}% confident!&#39; btn_upload = widgets.FileUpload() lbl_pred = widgets.Label() out_pl = widgets.Output() btn_run = widgets.Button(description = &#39;Classify&#39;) btn_run.on_click(classify) VBox([ widgets.Label(&#39;Upload a pet!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) . And there we have it! You can make it prettier and go win a hackathon. . However, a bit of a downside with deep learning is that it can only predict what it has been trained on. So, drawings of pets, night-time images of pets, and breeds that weren&#39;t included in the training set won&#39;t be accurately labelled. . We could solve the last case by turning this problem into a multi-label classification problem. Then, if we aren&#39;t confident that we have one of the known breeds, we can just say we don&#39;t know this breed. . Siamese Pair . When I was watching the fastai lectures, I heard Jeremy talking about &quot;siamese pairs&quot; where you give the model two images and it will tell you if they are of the same breed. Now that we have a model, let&#39;s make it! . def pair(a): if not up1.data or not up2.data: lbl.value = &#39;Please upload images.&#39; return im1 = PILImage.create(up1.data[-1]) im2 = PILImage.create(up2.data[-1]) pred1, x, _ = learn.predict(im1) pred2, y, _ = learn.predict(im2) out1.clear_output() out2.clear_output() with out1: display(im1.to_thumb(128, 128)) with out2: display(im2.to_thumb(128, 128)) if x == y: lbl.value = f&#39;Wow, they &#39;re both {pretty(pred1)}(s)!&#39; else: lbl.value = f&#39;The first one seems to be {pretty(pred1)} while the second one is a(n) {pretty(pred2)}. I &#39;m not an expert, but they seem to be of different breeds, chief.&#39; up1 = widgets.FileUpload() up2 = widgets.FileUpload() lbl = widgets.Label() out1 = widgets.Output() out2 = widgets.Output() run = widgets.Button(description = &#39;Classify&#39;) run.on_click(pair) VBox([ widgets.Label(&quot;Siamese Pairs&quot;), HBox([up1, up2]), run, HBox([out1, out2]), lbl ]) . You can now test out these cells here! .",
            "url": "https://geon-youn.github.io/DunGeon/2022/02/21/Pets.html",
            "relUrl": "/2022/02/21/Pets.html",
            "date": " • Feb 21, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Pixel Similarity vs. Basic Neural Net on the MNIST Dataset",
            "content": "Pixel Similarity . We will take the average of each digit to get its &quot;perfect&quot; version. Then, we compare an image to each of those perfect numbers and see which one is the most similar. . First, we&#39;ll download the MNIST dataset: . path = untar_data(URLs.MNIST) . The dataset is separated into training and testing subfolders, where in those folders, there are separate folders for each digit: . Path.BASE_PATH = path . path.ls(),(path/&#39;training&#39;).ls() . ((#2) [Path(&#39;testing&#39;),Path(&#39;training&#39;)], (#10) [Path(&#39;training/7&#39;),Path(&#39;training/8&#39;),Path(&#39;training/1&#39;),Path(&#39;training/6&#39;),Path(&#39;training/3&#39;),Path(&#39;training/2&#39;),Path(&#39;training/5&#39;),Path(&#39;training/4&#39;),Path(&#39;training/0&#39;),Path(&#39;training/9&#39;)]) . We&#39;ll store the path of each image in an array, where the ith row contains the path for the ith digit: . nums = [(path/&#39;training&#39;/f&#39;{x}&#39;).ls().sorted() for x in range(10)] . im3_path = nums[3][0] im3 = Image.open(im3_path) im3 . Then, we&#39;ll open the images, put every image of the same digit into their own tensor and store them as a list of tensors: . nums_tens = [torch.stack([tensor(Image.open(j)) for j in nums[i]]) for i in range(10)] nums_tens = [nums_tens[i].float()/255 for i in range(10)] . We can then take the mean of one of the tensors to get its &quot;perfect&quot; version. Here is how it looks like for a 3: . stacked_threes = nums_tens[3].mean(0) show_image(stacked_threes) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1e3d3acd0&gt; . And to compare, here is just one of those threes: . a_3 = nums_tens[3][0] show_image(a_3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1e36f1750&gt; . Next, we&#39;ll create a function that compares two tensors through absolute mean difference: . def mnist_distance(x1, x2): return (x1 - x2).abs().mean((-1, -2)) . Now we can compare one of the threes with its &quot;perfect&quot; version. The number doesn&#39;t really mean anything until we compare it with another number: . mnist_distance(a_3, stacked_threes) . tensor(0.1074) . So, we&#39;ll take the average seven and take the L1 norm (absolute mean difference) and compare that number with the number we just got (0.1074) . stacked_sevens = nums_tens[7].mean(0) show_image(stacked_sevens) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1e0401510&gt; . mnist_distance(a_3, stacked_sevens) . tensor(0.1441) . As you can see, the distance between the 3 and the average 3 is smaller than the distance between the 3 and the average 7. So, it is more three than seven. We&#39;ll extend this approach by comparing an image with the average for each digit and say it is the digit it is the most similar to (its L1 norm with that average digit is the smallest). . We&#39;ll create the average number for each digit: . stacked_nums = [nums_tens[i].mean(0) for i in range(10)] show_image(stacked_nums[4]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1e2b5e150&gt; . We can compare our 3 to each average digit: . L(mnist_distance(a_3, stacked_nums[i]) for i in range(10)) . (#10) [tensor(0.1750),tensor(0.1153),tensor(0.1501),tensor(0.1074),tensor(0.1635),tensor(0.1326),tensor(0.1579),tensor(0.1441),tensor(0.1345),tensor(0.1402)] . As you can see, it is most similar to the average three. . Now we&#39;ll import the validation set and put them into a list of tensors: . valid_nums = [(path/&#39;testing&#39;/f&#39;{i}&#39;).ls().sorted() for i in range(10)] . valid_nums_tens = [torch.stack([tensor(Image.open(j)) for j in valid_nums[i]]) for i in range(10)] valid_nums_tens = [valid_nums_tens[i].float()/255 for i in range(10)] . We&#39;ll create a function that returns the accuracy of our whole process: . def is_num(x1, x2s, x): # Get the distance between the number and the average digit for each digit vals = [mnist_distance(x1, x2s[i]) for i in range(10)] # Turn the tensors into floats so that we can perform the `min` function vals_2 = [[vals[i][j].item() for i in range(10)] for j in range(len(x1))] # Get a list of tensors that contain a bool value, where it&#39;s true when # the minimum distance is equal to the digit the given number is supposed # to be vals_3 = [tensor(vals_2[i].index(min(vals_2[i])) == x) for i in range(len(x1))] # Return how often our model is correct return tensor(vals_3).float().mean(0) . nums_accuracy = tensor([is_num(valid_nums_tens[i], stacked_nums, i) for i in range(10)]) nums_accuracy, nums_accuracy.mean(0) . (tensor([0.8153, 0.9982, 0.4234, 0.6089, 0.6680, 0.3262, 0.7871, 0.7646, 0.4425, 0.7760]), tensor(0.6610)) . Our model has an overall accuracy of 66.1%! Better than a random guess of 10%, but certainly not good. It is particularly good at guessing if a number is a 1, but particularly bad for 2s, 5s and 8s. . Now that we have a baseline, we can try how good we can get a simple model &quot;from scratch.&quot; . Basic Neural Net . For our &quot;from scratch&quot; learner, we&#39;ll have 2 layers, where each layer contains a linear layer and a ReLU (rectified linear unit, where all negative numbers become 0). . For our loss function, we will be using cross-entropy loss since we have multiple categories. . First, we&#39;ll make our training and validation datasets and dataloaders. Then, we&#39;ll initialize parameters, figure out how to make predictions, calculate the loss (cross-entropy), calculate the gradients, and then step (using the provided SGD optimizer). . Let&#39;s first redownload the MNIST dataset: . path = untar_data(URLs.MNIST) . Path.BASE_PATH = path . path.ls() . (#2) [Path(&#39;testing&#39;),Path(&#39;training&#39;)] . Then, we&#39;ll save the training and validation images into separate variables: . nums = [(path/&#39;training&#39;/f&#39;{x}&#39;).ls().sorted() for x in range(10)] . nums_tens = [torch.stack([tensor(Image.open(j)) for j in nums[i]]) for i in range(10)] nums_tens = [nums_tens[i].float()/255 for i in range(10)] . valid_nums = [(path/&#39;testing&#39;/f&#39;{i}&#39;).ls().sorted() for i in range(10)] . valid_nums_tens = [torch.stack([tensor(Image.open(j)) for j in valid_nums[i]]) for i in range(10)] valid_nums_tens = [valid_nums_tens[i].float()/255 for i in range(10)] . Next, we&#39;ll create our dataset from our training set. A dataset is a list of tuples, which contains the independent variable and its label (dependent variable) like so: (independent, dependent). . train_x = torch.cat(nums_tens).view(-1, 28*28) . It took a while for me to realize what the .view() function was doing, but what it does is pretty simple. We give it however many values we want (that makes sense) to change the shape of our tensor. Here we give it -1, 28*28 which will turn our rank-3 tensor (n-images of 28 by 28) into a rank-2 tensor (n-images of 28*28). -1 makes it so that we don&#39;t have to specify how many images there are and 28*28 means we want to compress our previous 28 by 28 grid into a 28*28 vector. It&#39;s like turning a 2D array into a 1D array: . # -1 makes it so that we don&#39;t have to know how many images there are nums_tens[0].view(-1, 28*28).shape, nums_tens[0].view(5923, 28*28).shape . (torch.Size([5923, 784]), torch.Size([5923, 784])) . # before we called .view(), our tensor was originally 28x28, but afterwards, it is 28*28 (784) nums_tens[0].size(), nums_tens[0].view(-1, 28*28).shape . (torch.Size([5923, 28, 28]), torch.Size([5923, 784])) . We&#39;ll form our labels by having as many tensors containing the digit&#39;s digit as there are of that digit: . train_y = torch.cat([tensor([i] * len(nums_tens[i])) for i in range(10)]) . train_x.shape, train_y.shape . (torch.Size([60000, 784]), torch.Size([60000])) . # when we take a random 3, we can index into the labels at the same spot and see # that we can 3 as its label show_image(nums_tens[3][200]), train_y[len(nums_tens[0]) + len(nums_tens[1]) + len(nums_tens[2]) +200] . (&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1e2aa69d0&gt;, tensor(3)) . Like I said before, a dataset is just a list of tuples containing our independent and dependent variables: . dset = list(zip(train_x, train_y)) x, y = dset[0] x.shape, y . (torch.Size([784]), tensor(0)) . And we can see that given a label 0, our image is indeed a zero: . # we have to reshape our image from a 784 long vector into a 28*28 matrix show_image(x.view(28, 28)) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb1d9324110&gt; . Now we&#39;ll make the dataset for our validation set: . valid_x = torch.cat(valid_nums_tens).view(-1, 28*28) valid_y = torch.cat([tensor([i] * len(valid_nums_tens[i])) for i in range(10)]) valid_dset = list(zip(valid_x, valid_y)) . Next, we&#39;ll create DataLoaders for our training and validation sets. A DataLoader takes a dataset and each time we use it, it will give a portion of the dataset. We can then work on a portion of the dataset instead of just 1 tuple or the entire set. We can also toggle whether we want our given portion to be randomize (we wouldn&#39;t want to get all 0s, then 1s, then 2s, ... we want a mix): . dl = DataLoader(dset, batch_size = 128, shuffle = True) valid_dl = DataLoader(valid_dset, batch_size = 128, shuffle = True) xb, yb = first(dl) xb.shape, yb.shape . (torch.Size([128, 784]), torch.Size([128])) . Then, we&#39;ll create our DataLoaders. A DataLoaders is like the dataset of a DataLoader: it just contains our training and validation DataLoaders: . dls = DataLoaders(dl, valid_dl) . Our simple neural network uses PyTorch&#39;s nn.Sequential which takes modules and uses the GPU to handle the operations: . simple_net = nn.Sequential( # Our first layer takes in 28*28 inputs and outputs 250 nn.Linear(28 * 28, 250), nn.ReLU(), # Our second layer takes in 250 inputs and outputs 50 nn.Linear(250, 50), nn.ReLU(), # Our final layer takes in 50 inputs and outputs 10 # (its confidence for our image to be each digit) nn.Linear(50, 10) ) . We use cross-entropy loss so that we can turn our 10 outputs into numbers that are from 0 to 1 and sum to 1 like probabilities (through softmax). But, that&#39;s just the first part. We then take the negative log (-log(p)) of those probabilities to give emphasis on the higher probabilities. . We&#39;ll use the given Learner class from fastai (which handles epochs) with the SGD optimizer (stochastic gradient descent, which handles calculating gradients and stepping into lower loss) and use the accuracy metric (the number we care about). . learn = Learner(dls, simple_net, opt_func = SGD, loss_func = F.cross_entropy, metrics = accuracy) . We&#39;ll use the learning rate finder to select a good learning rate for us: . lrs = learn.lr_find() lrs . SuggestedLRs(valley=0.04786301031708717) . learn.fit(20, lr = lrs.valley) . epoch train_loss valid_loss accuracy time . 0 | 0.454874 | 0.400172 | 0.889500 | 00:02 | . 1 | 0.322119 | 0.292965 | 0.916900 | 00:02 | . 2 | 0.264725 | 0.245524 | 0.929800 | 00:02 | . 3 | 0.228520 | 0.216811 | 0.938200 | 00:02 | . 4 | 0.196191 | 0.187768 | 0.945100 | 00:02 | . 5 | 0.181299 | 0.170362 | 0.950000 | 00:02 | . 6 | 0.151747 | 0.152564 | 0.954600 | 00:02 | . 7 | 0.143972 | 0.141233 | 0.957100 | 00:02 | . 8 | 0.125890 | 0.130209 | 0.961300 | 00:02 | . 9 | 0.119570 | 0.117828 | 0.964100 | 00:02 | . 10 | 0.112297 | 0.120144 | 0.963900 | 00:02 | . 11 | 0.096248 | 0.108321 | 0.967100 | 00:02 | . 12 | 0.085236 | 0.100657 | 0.970100 | 00:02 | . 13 | 0.082346 | 0.094316 | 0.970200 | 00:02 | . 14 | 0.077736 | 0.090774 | 0.972000 | 00:02 | . 15 | 0.075661 | 0.093964 | 0.971500 | 00:02 | . 16 | 0.064168 | 0.087111 | 0.973000 | 00:02 | . 17 | 0.062180 | 0.080836 | 0.975900 | 00:02 | . 18 | 0.061466 | 0.077446 | 0.977300 | 00:02 | . 19 | 0.052969 | 0.078910 | 0.975300 | 00:02 | . And we see that our final accuracy is 97.5%! Certainly better than the 66.1% we got from our pixel similarity approach. . To compare, here&#39;s the results using fastai&#39;s provided cnn_learner which uses a pretrained model with 18 layers: . dls2 = ImageDataLoaders.from_folder(path, train=&#39;training&#39;, valid=&#39;testing&#39;) learn2 = cnn_learner(dls2, resnet18, loss_func=F.cross_entropy, metrics=accuracy) learn2.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.124300 | 0.056642 | 0.982900 | 02:04 | . Our model is not bad considering it&#39;s less than 1% in accuracy different from a pretrained model. . We could even make our model better by training for more epochs until the validation loss becomes worse or by using a deeper model. .",
            "url": "https://geon-youn.github.io/DunGeon/2022/02/20/MNIST.html",
            "relUrl": "/2022/02/20/MNIST.html",
            "date": " • Feb 20, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hello! . My name is Geon and I am an 18 year old Korean-Canadian. I graduated Westdale S.S. in 2021 and am currently attending McMaster University for computer science. I started fast.ai when I was in 12th grade and here I am continuing to learn about deep learning and now I am starting a blog. .",
          "url": "https://geon-youn.github.io/DunGeon/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://geon-youn.github.io/DunGeon/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}